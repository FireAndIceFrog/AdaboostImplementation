{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignement 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the assigment 1 by Mathew Lawrence 17354272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from os import path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating our own adabooster class. This will handle the adabooster for each scenario.\n",
    "\n",
    "For multiple types, we will create an adabooster which classifies \"that\" or \"not that\", respectfully, and then compare them to each other.\n",
    "\n",
    "The adabooster is a copy of tutorial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adabooster:\n",
    "    def __init__(self,debug = False, file = \"\"):\n",
    "        self.debug = debug\n",
    "        self.marginDF = None\n",
    "        self.classifier_df = None\n",
    "        self.file = file\n",
    "        self.fitNumber = 0\n",
    "        return\n",
    "    def saveClassifier(self, file=\"\"):\n",
    "        if(file!=\"\"):\n",
    "            self.file = file\n",
    "        self.classifier_df = pd.DataFrame(np.concatenate((self.h,np.expand_dims(self.alpha, axis=1)), axis = 1) , columns = [\"Threshold\",\"Feature\",\"Direction\",\"Alpha\"])\n",
    "        self.classifier_df.to_csv(self.file)\n",
    "    def loadClassifier(self,file = \"\"):\n",
    "        if(file!=\"\"):\n",
    "            self.file = file\n",
    "        self.classifier_df = pd.read_csv(self.file,index_col = 0)\n",
    "        \n",
    "    def reset_params(self,Tt, datat):\n",
    "        'Reset the parameters for the booster round'\n",
    "        \n",
    "        self.T = Tt\n",
    "        self.h  = np.zeros([self.T, 3], dtype=np.float64)\n",
    "        self.alpha  = np.zeros(self.T, dtype=np.float64)\n",
    "        self.err  = np.ones(self.T, dtype=np.float64) * np.inf\n",
    "        self.weight  = np.ones(datat.shape[0], dtype=np.float64) / datat.shape[0]\n",
    "        self.dim = datat.shape[1]\n",
    "        \n",
    "    def calculate_decision_stump_bad(self,x, w, l):\n",
    "                        # data x\n",
    "                        # weights w\n",
    "                        # labels l\n",
    "    \n",
    "        min_error = np.float64(np.inf)\n",
    "        best_thresh = 0\n",
    "        best_dir = 0\n",
    "        interval = np.abs(x.max() - x.min()) / 100.0\n",
    "        if(interval == 0):\n",
    "            return 0,1,np.inf\n",
    "        threshold = np.arange(x.min()-interval*2.0, x.max()+interval*2.0, interval)\n",
    "        temp_err = np.float64(0)\n",
    "\n",
    "        for d in [1, -1]:\n",
    "            for thresh in threshold:\n",
    "\n",
    "                temp = np.zeros(len(x), dtype=np.int64)\n",
    "                if(d == 1):\n",
    "                    temp = (x >= thresh)\n",
    "                else:\n",
    "                    temp = (x < thresh)\n",
    "\n",
    "                temp = np.int64(temp)\n",
    "                temp[np.where(temp == 0)] = -1\n",
    "\n",
    "                # Initialise actual and expected labels to a perfect match( 0 = match , 1 = not a match)\n",
    "                y = np.zeros(len(x), dtype=np.int64)            \n",
    "                # y will be an array where 0 indictes that the sample has been correctly classified, otherwise 1\n",
    "                y = np.int64(temp != l)\n",
    "\n",
    "                # Calculate error of this weak classifier on the weighted dataset\n",
    "                #========================\n",
    "                #YOUR CODE HERE\n",
    "                #========================\n",
    "                temp_err = np.sum(y * w)\n",
    "\n",
    "                if temp_err < min_error:\n",
    "                    #========================\n",
    "                    #YOUR CODE HERE\n",
    "                    #========================\n",
    "                    min_error = temp_err\n",
    "                    best_thresh = thresh\n",
    "                    best_dir = d                \n",
    "\n",
    "        return  best_thresh, best_dir, min_error\n",
    "    \n",
    "    def calculate_decision_stump(self,data, feature, weight, label):\n",
    "        'Calculate the desicion stump for the next booster round'\n",
    "        Tp=np.float64(0); #T+ total sum of positive examples weights\n",
    "        Tn=np.float64(0) #T- total sum of negative examples weights\n",
    "        Sp=np.float64(0) #S+ sum of positive weights below the cuurent threshold\n",
    "        Sn=np.float64(0) #S- sum of negative weights below the current threshold\n",
    "        error1=np.float64(0)\n",
    "        error2=np.float64(0)\n",
    "        min_error=np.float64(100) \n",
    "        min_thresh=np.float64(0) \n",
    "        direction=1\n",
    "\n",
    "        y = np.zeros(data.shape[0], dtype=np.int64)\n",
    "\n",
    "        #get all positive weights    \n",
    "        temp  = (label == 1)\n",
    "        temp = np.int64(temp)\n",
    "        Tp = np.sum(temp * weight)\n",
    "\n",
    "        #get all negative weights  \n",
    "        temp  = (label == -1)\n",
    "        temp = np.int64(temp)\n",
    "        Tn = np.sum(temp * weight)\n",
    "\n",
    "        #sort feature values\n",
    "        sorted_labels = data[:, feature].argsort()\n",
    "        sorted_vector =  data[sorted_labels]\n",
    "\n",
    "        length = len(sorted_vector)\n",
    "        for i in range(length):\n",
    "\n",
    "            #RIGHT DIRECTION THRESHOLD\n",
    "            #error1 is the sum of positives up to that point + total negatives minus the sum of negatives so far\n",
    "            error1 = Sp + (Tn - Sn) \n",
    "            if label[sorted_labels[i]] == -1 : \n",
    "                Sn = Sn +  weight[sorted_labels[i]]\n",
    "            else :\n",
    "                Sp = Sp + weight[sorted_labels[i]]\n",
    "\n",
    "            #LEFT DIRECTION THRESHOLD\n",
    "            error2 = Sn + (Tp - Sp) \n",
    "\n",
    "            if(min_error > error1) :\n",
    "                min_error = error1\n",
    "                min_thresh = sorted_vector[i, feature]\n",
    "                direction = 1\n",
    "            if(min_error > error2) :\n",
    "                min_error = error2\n",
    "                min_thresh = sorted_vector[i, feature]\n",
    "                direction = -1           \n",
    "        \n",
    "        return min_thresh, direction, min_error\n",
    "    def calculate_alpha(self,weighted_error):    \n",
    "        #========================\n",
    "        #YOUR CODE HERE\n",
    "        #========================\n",
    "        if(wighted_error == 0):\n",
    "            return 1\n",
    "        return  0.5 * np.log( (1.0 - weighted_error) / weighted_error )\n",
    "    \n",
    "    def classify_dataset_against_weak_classifier(self,x, thresh, direction):\n",
    "        classification = np.zeros(len(x))\n",
    "\n",
    "        #classifiy all samples based on the last feature\n",
    "        #get actual classification\n",
    "        for i in range(len(x)):\n",
    "            #========================\n",
    "            #YOUR CODE HERE\n",
    "            #========================\n",
    "            if direction == -1:\n",
    "                if x[i] < thresh: classification[i] = 1\n",
    "                else : classification[i] = -1\n",
    "            else:\n",
    "                if x[i] < thresh: classification[i] = -1\n",
    "                else : classification[i] = 1    \n",
    "\n",
    "\n",
    "        return classification \n",
    "    def update_weights(self,weight, alpha, classification, label):\n",
    "\n",
    "        for i in range(len(weight)):\n",
    "            #========================\n",
    "            #YOUR CODE HERE\n",
    "            #========================\n",
    "            weight[i] =  weight[i] * np.exp( -1.0 * alpha * classification[i] * label[i] ) \n",
    "\n",
    "        return weight\n",
    "    def normalise_weights(self,weight):\n",
    "\n",
    "        #========================\n",
    "        #YOUR CODE HERE\n",
    "        #========================\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        return weight \n",
    "    def fit(self, x , label ):\n",
    "        # This is for future use\n",
    "        if(path.exists(self.file+str(self.fitNumber)+\".csv\")):\n",
    "            self.loadClassifier(self.file+str(self.fitNumber)+\".csv\")\n",
    "        else:\n",
    "            T = self.T\n",
    "            h = self.h\n",
    "            alpha = self.alpha\n",
    "            err = self.err\n",
    "            weight = self.weight\n",
    "\n",
    "            #0 - for each boosting round\n",
    "            for t in range(T): \n",
    "                #1 - iterate through every feature  \n",
    "\n",
    "\n",
    "                for feature in range(self.dim): \n",
    "                    weighted_error = np.float64(0)\n",
    "\n",
    "                    #========================\n",
    "                    #2 - GENERATE A DECISION STUMP FOR A FEATURE\n",
    "                    #YOUR CODE HERE\n",
    "                    #========================\n",
    "                    threshold, sign, weighted_error = self.calculate_decision_stump_bad(x[:,feature] , weight, label)\n",
    "    #                 threshold, sign, weighted_error = self.calculate_decision_stump(x , feature, weight, label)\n",
    "    #                 print(\"Iteration: \",t,\"Feature: \",feature, \" Weighted err: \", weighted_error)\n",
    "                    #========================\n",
    "                    #3 - KEEP TRACK OF THE FEATURE WITH THE LOWEST WEIGHTED ERROR\n",
    "                    #YOUR CODE HERE\n",
    "                    #========================        \n",
    "                    if weighted_error < err[t] :\n",
    "                        err[t] = weighted_error\n",
    "                        h[t][0] = threshold\n",
    "                        h[t][1] = feature\n",
    "                        h[t][2] = sign\n",
    "\n",
    "    #             print(\"---->Chosen ERR: \", err[t])\n",
    "                #========================\n",
    "                #4 - CALCULATE ALPHA FOR BOOSTING ROUND t\n",
    "                #YOUR CODE HERE\n",
    "                #========================            \n",
    "                alpha[t] = self.calculate_alpha(err[t])\n",
    "                #========================\n",
    "                #5 - CLASSIFY ALL SAMPLES BASED ON THE SELECTED FEATURE FOR BOOSTING ROUND t\n",
    "                #YOUR CODE HERE\n",
    "                #======================== \n",
    "                #print(x[:, int(h[t][1]) ])\n",
    "                classification = self.classify_dataset_against_weak_classifier(x[:, int(h[t][1]) ], h[t][0], h[t][2] )\n",
    "\n",
    "                #========================\n",
    "                #6 - UPDATE WEIGHTS BASED ON THE CORRECTNESS OF THE CLASSIFICATION\n",
    "                #YOUR CODE HERE\n",
    "                #========================   \n",
    "                weight = self.update_weights(weight, alpha[t], classification, label)\n",
    "\n",
    "                #========================\n",
    "                #7 - NORMALISE REASSIGNED WEIGHTS\n",
    "                #YOUR CODE HERE\n",
    "                #========================  \n",
    "                weight = self.normalise_weights(weight )\n",
    "\n",
    "                #--------------------------------------------\n",
    "                #BOOSTING ALGORITHM DONE\n",
    "                #--------------------------------------------\n",
    "                if(err[t]==0):\n",
    "                    break\n",
    "\n",
    "                if (self.debug):\n",
    "                    print(\"Round \",t, \" Done!\")\n",
    "            self.T = T\n",
    "            self.h = h\n",
    "            self.alpha =  alpha\n",
    "            self.err = err\n",
    "            self.weight = weight \n",
    "            self.saveClassifier(self.file+str(self.fitNumber)+\".csv\")\n",
    "        self.fitNumber = self.fitNumber+1\n",
    "#         self.classifier_df = pd.DataFrame(np.concatenate((self.h,np.expand_dims(self.alpha, axis=1)), axis = 1) , columns = [\"Threshold\",\"Feature\",\"Direction\",\"Alpha\"])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def classify_sample(self,xi ):\n",
    "        boost_classif = self.classifier_df\n",
    "        boost_classif = boost_classif.values\n",
    "        classification_sum = np.float64(0)\n",
    "\n",
    "        for thresh, feat, sign, alpha in boost_classif:\n",
    "            feat = np.int64(feat)\n",
    "            temp = np.float64(0)\n",
    "            if(sign == 1):\n",
    "                temp = (xi[feat] >= thresh)\n",
    "            else:\n",
    "                temp =  (xi[feat]< thresh)\n",
    "\n",
    "            temp = alpha*(-1 if temp == 0 else temp)\n",
    "\n",
    "\n",
    "            classification_sum = classification_sum + temp\n",
    "\n",
    "\n",
    "        if classification_sum >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    def classify_dataset(self,test_x):\n",
    "        results = []\n",
    "        for i in range(len(test_x)):\n",
    "            results.append(self.classify_sample(test_x[i]))\n",
    "        results = np.array(results)\n",
    "        return results\n",
    "    def score(self,test_x,test_y):\n",
    "        results=self.classify_dataset(test_x)\n",
    "        score = len(results[results == test_y])/len(results*100)\n",
    "        print(score)\n",
    "        return  score\n",
    "    def sum_classifier_votes_for_each_sample(self, dataset, df):\n",
    "        classifier_df = self.classifier_df\n",
    "        for i in range(len(dataset)):\n",
    "            classification_sum = np.float64(0)\n",
    "            neg_votes = np.float64(0)\n",
    "            pos_votes = np.float64(0)\n",
    "            for idx, thresh, feat, sign, alpha in classifier_df.itertuples():\n",
    "                #========================\n",
    "                #YOUR CODE HERE\n",
    "                #========================  \n",
    "                feat = np.int64(feat)\n",
    "                temp = np.float64(0)\n",
    "                if(sign == 1):\n",
    "                    temp = (dataset[i][feat] >= thresh)\n",
    "                else:\n",
    "                    temp =  (dataset[i][feat]< thresh)\n",
    "\n",
    "                temp = alpha*(-1 if temp == 0 else temp)\n",
    "                if temp < 0:\n",
    "                    neg_votes = neg_votes+temp\n",
    "                else : \n",
    "                    pos_votes = pos_votes +temp\n",
    "\n",
    "\n",
    "\n",
    "                classification_sum = classification_sum + temp\n",
    "\n",
    "\n",
    "            #========================\n",
    "            #YOUR CODE HERE\n",
    "            #========================  \n",
    "            df['sum_alpha'].iloc[i] = classification_sum\n",
    "            df['pos_votes'].iloc[i] = pos_votes\n",
    "            df['neg_votes'].iloc[i] = neg_votes\n",
    "\n",
    "        return df\n",
    "    def margin_calculation(self,sign, pos, neg, tot_votes):\n",
    "        #========================\n",
    "        #YOUR CODE HERE\n",
    "        #========================   \n",
    "        margin = (pos/tot_votes if sign>0 else neg/tot_votes)\n",
    "\n",
    "        return margin\n",
    "    def margin_calculation_for_training_samples(self, sign, pos, neg, tot_votes ):  \n",
    "        if np.sign(sign) < 0:\n",
    "            return np.abs(neg) / tot_votes, -1\n",
    "        else:\n",
    "            return pos / tot_votes, 1\n",
    "    def sign_of_margin(self, margin, classification, true_class_label):\n",
    "        #========================\n",
    "        #YOUR CODE HERE\n",
    "        #========================      \n",
    "        return (margin if (classification == true_class_label) else -margin)\n",
    "    def calculate_margins(self,x,label):\n",
    "        testing_set_df = pd.DataFrame(x)\n",
    "        testing_set_df['sum_alpha'] = 0 \n",
    "        testing_set_df['pos_votes'] = 0 \n",
    "        testing_set_df['neg_votes'] = 0 \n",
    "\n",
    "        testing_set_df = self.sum_classifier_votes_for_each_sample(x, testing_set_df)\n",
    "#         total_alpha_votes = np.sum(self.classifier_df.Alpha)\n",
    "#         testing_set_df['classification'] = 0\n",
    "#         testing_set_df['margin'] = 0\n",
    "#         testing_set_df['total_alpha_votes'] = total_alpha_votes\n",
    "        \n",
    "#         result = testing_set_df[['sum_alpha','pos_votes','neg_votes','total_alpha_votes']].apply(lambda x: self.margin_calculation_for_training_samples(*x), axis=1)\n",
    "#         testing_set_df['margin'] = result.apply(lambda x: x[0])\n",
    "#         testing_set_df['classification'] = result.apply(lambda x: x[1])\n",
    "#         testing_set_df['true_class_label'] = label\n",
    "        \n",
    "#         testing_set_df['sign_of_margin'] = testing_set_df[['margin', 'classification', 'true_class_label']].apply(lambda x: self.sign_of_margin(*x), axis=1)\n",
    "#         self.marginDF = testing_set_df[['sign_of_margin']]\n",
    "        self.marginDF =  testing_set_df\n",
    "        return testing_set_df\n",
    "    def plotMargins(self):\n",
    "        margin_30 = self.marginDF[[\"sign_of_margin\"]]\n",
    "        sns.kdeplot(margin_30.sign_of_margin, cumulative=True, label='classifier size 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X,Y,K=3):\n",
    "    'Split the data into train and test splits. They will be split into K buckets, with the K-1 bucket as the test dataset.'\n",
    "    kf = KFold(n_splits=K)\n",
    "    Y_correct = Y[Y==1]\n",
    "    Y_incorrect = Y[Y==-1]\n",
    "    X_correct = X[Y==1]\n",
    "    X_incorrect = X[Y==-1]\n",
    "\n",
    "    train_x = []\n",
    "    test_x = []\n",
    "    train_y = []\n",
    "    test_y = []\n",
    "\n",
    "    # Add the correct rows\n",
    "    for train_index, test_index in kf.split(Y_correct):\n",
    "        X_train, X_test = X_correct[train_index], X_correct[test_index]\n",
    "        y_train, y_test = Y_correct[train_index], Y_correct[test_index]\n",
    "\n",
    "        train_x.append(X_train)\n",
    "        test_x.append(X_test)\n",
    "        train_y.append(y_train)\n",
    "        test_y.append(y_test)\n",
    "    #     Add the incorrect rows\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(Y_incorrect):\n",
    "        X_train, X_test = X_incorrect[train_index], X_incorrect[test_index]\n",
    "        y_train, y_test = Y_incorrect[train_index], Y_incorrect[test_index]\n",
    "\n",
    "        train_x[i] = np.append(train_x[i], X_train, axis=0)   \n",
    "        test_x[i] = np.append(test_x[i],X_test, axis=0)\n",
    "        train_y[i] = np.append(train_y[i],y_train, axis=0)\n",
    "        test_y[i]= np.append(test_y[i],y_test, axis=0)\n",
    "        i = i + 1\n",
    "#     Make sure that all the indexes are the same.\n",
    "    minIndex =1000000000;\n",
    "    for i in range(len(train_x)):\n",
    "        if(train_x[i].shape[0] < minIndex):\n",
    "            minIndex = train_x[i].shape[0]\n",
    "    for i in range(len(train_x)):\n",
    "        train_x[i] = train_x[i][:minIndex]\n",
    "        train_y[i] = train_y[i][:minIndex]\n",
    "        \n",
    "    return \\\n",
    "    (train_x,\n",
    "    test_x,\n",
    "    train_y,\n",
    "    test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SPAM dataset should be placed in its own folder. Initiate it as SPAM_X and SPAM_Y, the input and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamDF = pd.read_csv(\"spambase.data\", header = None,index_col=False)\n",
    "SPAM_X = spamDF[list(range(len(spamDF.columns)-1))].values\n",
    "SPAM_Y = spamDF[len(spamDF.columns)-1].apply(lambda a: 1 if a==1 else -1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1:  0.6059552271245382\n",
      "1:  0.39404477287546186\n"
     ]
    }
   ],
   "source": [
    "print(\"-1: \",len(SPAM_X[SPAM_Y==-1])/len(SPAM_X))\n",
    "print(\"1: \",len(SPAM_X[SPAM_Y==1])/len(SPAM_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the SPAM dataset is skewed. we will have to make our bins with the same skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,    test_x,    train_y,    test_y = train_test_split(SPAM_X,SPAM_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1:  0.6060013046314416\n",
      "1:  0.39399869536855836\n"
     ]
    }
   ],
   "source": [
    "print(\"-1: \",len(train_y[0][train_y[0] == -1])/len(train_y[0]))\n",
    "print(\"1: \",len(train_y[0][train_y[0] == 1])/len(train_y[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataframe for the scores for the custom and the skikit adabooster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 60\n",
    "CUSTOM_SPAM_SCORES = []\n",
    "ADABOOST_SPAM_SCORES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "custSpamBoost = adabooster(False,\"spam\")\n",
    "custSpamBoost.reset_params(rounds, train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9224755700325733\n",
      "0.9282452707110241\n",
      "0.7945205479452054\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(train_x)):\n",
    "    custSpamBoost.fit(train_x[i], train_y[i])\n",
    "    CUSTOM_SPAM_SCORES.append( custSpamBoost.score(test_x[i],test_y[i]))\n",
    "CUSTOM_SPAM_SCORES = np.array(CUSTOM_SPAM_SCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92247557, 0.92824527, 0.79452055])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSTOM_SPAM_SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[\"cust_spam_std\"] = CUSTOM_SPAM_SCORES.std()\n",
    "scores[\"cust_spam_mean\"] = CUSTOM_SPAM_SCORES.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit learn adabooster Spam database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cust_spam_std': 0.06172346807611869, 'cust_spam_mean': 0.8817471295629343}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciSpamBoost = AdaBoostClassifier(n_estimators=rounds, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_spam_scores = []\n",
    "for i in range(len(train_x)):\n",
    "    sciSpamBoost.fit(train_x[i], train_y[i])\n",
    "    sci_spam_scores.append(sciSpamBoost.score(test_x[i], test_y[i]))\n",
    "sci_spam_scores = np.array(sci_spam_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[\"sci_spam_std\"] = sci_spam_scores.std()\n",
    "scores[\"sci_spam_mean\"] = sci_spam_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cust_spam_std': 0.06172346807611869,\n",
       " 'cust_spam_mean': 0.8817471295629343,\n",
       " 'sci_spam_std': 0.05148765507554833,\n",
       " 'sci_spam_mean': 0.91544160924376}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['CUST_SPAM','Skikit-SPAM']\n",
    "\n",
    "ax.bar(langs,[scores[\"cust_spam_mean\"],scores[\"sci_spam_mean\"]],yerr = [scores[\"cust_spam_std\"],scores[\"sci_spam_std\"]], width = 0.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris database has got 3 classes. as such we will train 3 adaboosters and resolve conflicts using the sum of alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisDF = pd.read_csv(\"iris.data\", header = None,index_col=False)\n",
    "irisDF[len(irisDF.columns)-1] = irisDF[len(irisDF.columns)-1].apply(lambda x: 0 if x=='Iris-setosa'  else (1 if x=='Iris-versicolor' else 2))\n",
    "\n",
    "irisDF\n",
    "X = irisDF[list(range(len(irisDF.columns)-1))].values\n",
    "Y = irisDF[len(irisDF.columns)-1].values\n",
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3  4\n",
       "0    5.1  3.5  1.4  0.2  0\n",
       "1    4.9  3.0  1.4  0.2  0\n",
       "2    4.7  3.2  1.3  0.2  0\n",
       "3    4.6  3.1  1.5  0.2  0\n",
       "4    5.0  3.6  1.4  0.2  0\n",
       "..   ...  ...  ...  ... ..\n",
       "145  6.7  3.0  5.2  2.3  2\n",
       "146  6.3  2.5  5.0  1.9  2\n",
       "147  6.5  3.0  5.2  2.0  2\n",
       "148  6.2  3.4  5.4  2.3  2\n",
       "149  5.9  3.0  5.1  1.8  2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function to split the groups into however many classes there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataOrganizer:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        \n",
    "    def split_into_classes(self):\n",
    "        numClasses = self.df[len(self.df.columns)-1].unique()\n",
    "        classDF = []\n",
    "        for classID in numClasses:\n",
    "            dummyDF = self.df.copy()\n",
    "            dummyDF[len(dummyDF.columns)-1] = dummyDF[len(dummyDF.columns)-1].apply(lambda x: 1 if x == classID else -1)\n",
    "            classDF.append(dummyDF)\n",
    "        self.classDF = classDF\n",
    "    def generate_train_test_splits_for_classes(self, K=3):\n",
    "        'function to create a train and test split for each of the classes/adaboosters'\n",
    "        classTrainTests = []\n",
    "        for i in range(len(self.classDF)):\n",
    "\n",
    "            X = self.classDF[i][list(range(len(self.classDF[i].columns)-1))].values\n",
    "            Y = self.classDF[i][len(self.classDF[i].columns)-1].apply(lambda a: 1 if a==1 else -1).values\n",
    "\n",
    "            train_x,    test_x,    train_y,    test_y = train_test_split(X,Y,K)\n",
    "            \n",
    "            classTrainTests.append( {\n",
    "                \"train_x\" : train_x,\n",
    "                \"train_y\" : train_y,\n",
    "                \"test_x\" : test_x,\n",
    "                \"test_y\" : test_y\n",
    "            } )\n",
    "#         find the minimum for the train_x\n",
    "        minLen = np.inf\n",
    "        for i in range(len(self.classDF)):\n",
    "            for j in range(K):\n",
    "                currLen = len(classTrainTests[i][\"train_x\"][j])\n",
    "                if(minLen > currLen ):\n",
    "                    minLen = currLen\n",
    "        print(minLen)\n",
    "        for i in range(len(self.classDF)):\n",
    "            for j in range(K):\n",
    "                classTrainTests[i][\"train_x\"][j] = classTrainTests[i][\"train_x\"][j][:minLen]\n",
    "                classTrainTests[i][\"train_y\"][j] = classTrainTests[i][\"train_y\"][j][:minLen]\n",
    "                \n",
    "        minLen = np.inf   \n",
    "        for i in range(len(self.classDF)):\n",
    "            for j in range(K):\n",
    "                currLen = len(classTrainTests[i][\"test_x\"][j])\n",
    "                if(minLen > currLen ):\n",
    "                    minLen = currLen\n",
    "                    \n",
    "        for i in range(len(self.classDF)):\n",
    "            for j in range(K):\n",
    "                classTrainTests[i][\"test_x\"][j] = classTrainTests[i][\"test_x\"][j][:minLen]\n",
    "                classTrainTests[i][\"test_y\"][j] = classTrainTests[i][\"test_y\"][j][:minLen]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        self.classTrainTests = classTrainTests\n",
    "        return classTrainTests\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Organizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data organizer is used to split the data into class DF's (binary DF's) and generates N Dataframes where N = number of classes\n",
    "\n",
    "Next it splits the classes further into K-fold train/test splits\n",
    "\n",
    "\n",
    "In other words:\n",
    "1.) A DF with 3 classes is split into 3 DFs\n",
    "2.) Each DF is then split into K test/train splits of the order:\n",
    "Class:\n",
    "    train_x;\n",
    "        data\n",
    "        data\n",
    "        data\n",
    "    train_y;\n",
    "        data\n",
    "        data\n",
    "        data\n",
    "    test_x;\n",
    "        data\n",
    "        data\n",
    "        data\n",
    "    test_y;\n",
    "        data\n",
    "        data\n",
    "        data\n",
    "     ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGenerator = DataOrganizer(irisDF)\n",
    "dataGenerator.split_into_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "classTrainTests = dataGenerator.generate_train_test_splits_for_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train_x': [array([[5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3],\n",
       "          [6.5, 3. , 5.5, 1.8],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8]]),\n",
       "   array([[5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3]]),\n",
       "   array([[5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4]])],\n",
       "  'train_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)],\n",
       "  'test_x': [array([[5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ]]),\n",
       "   array([[5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3]]),\n",
       "   array([[4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8]])],\n",
       "  'test_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)]},\n",
       " {'train_x': [array([[5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3],\n",
       "          [6.5, 3. , 5.5, 1.8],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8]]),\n",
       "   array([[7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3]]),\n",
       "   array([[7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4]])],\n",
       "  'train_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)],\n",
       "  'test_x': [array([[7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4]]),\n",
       "   array([[5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3]]),\n",
       "   array([[5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8]])],\n",
       "  'test_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)]},\n",
       " {'train_x': [array([[7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3]]),\n",
       "   array([[6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3],\n",
       "          [6.5, 3. , 5.5, 1.8],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1]]),\n",
       "   array([[6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3],\n",
       "          [6.5, 3. , 5.5, 1.8],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3]])],\n",
       "  'train_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)],\n",
       "  'test_x': [array([[6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3],\n",
       "          [6.5, 3. , 5.5, 1.8],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4]]),\n",
       "   array([[7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4]]),\n",
       "   array([[6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3]])],\n",
       "  'test_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classTrainTests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Adabooster\n",
    "Create a class which handles multiple adaboost classes and train it.\n",
    "\n",
    "The fit function fits the data to each model and it also scores the model each round.\n",
    "\n",
    "At the end it returns an array of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiAdabooster:\n",
    "    def __init__(self,numClasses, file):\n",
    "        self.boosterList = []\n",
    "        for i in range(numClasses):\n",
    "            self.boosterList.append(adabooster(False,file+str(i)))\n",
    "        \n",
    "    def reset_params(self, Tt, datat):\n",
    "        for i in range(len(self.boosterList)):\n",
    "            self.boosterList[i].reset_params(Tt, datat)\n",
    "    def fit(self,classData,rootFile = \"\"):\n",
    "        scores = []\n",
    "#     For each fold\n",
    "        for i in range(len(classData[0][\"train_x\"])):\n",
    "#         for each class fit\n",
    "            for boostClass in range(len(self.boosterList)):\n",
    "                train_x = classData[boostClass][\"train_x\"][i]\n",
    "                train_y = classData[boostClass][\"train_y\"][i]\n",
    "                self.boosterList[boostClass].fit(train_x,train_y)\n",
    "#         Set the margins for the classifier\n",
    "            results = []\n",
    "            for boostClass in range(len(self.boosterList)):\n",
    "                test_x = classData[boostClass][\"test_x\"][i]\n",
    "                test_y = classData[boostClass][\"test_y\"][i]\n",
    "                self.boosterList[boostClass].calculate_margins(test_x,test_y)\n",
    "                results.append(self.boosterList[boostClass].classify_dataset(test_x))\n",
    "#             use sum of alpha votes, if sum is greater, use that one.\n",
    "            for baseClass in range(len(results)):\n",
    "                baseAlphas = self.boosterList[baseClass].marginDF['sum_alpha']\n",
    "                for testClass in range(len(results)):\n",
    "                    if(testClass == baseClass):\n",
    "                        continue\n",
    "                    \n",
    "                    testAlphas = self.boosterList[testClass].marginDF['sum_alpha']\n",
    "                    for idx in range(len(results[baseClass])):\n",
    "                        if((results[baseClass][idx] == 1) and (results[testClass][idx]==1)):\n",
    "#                             get the sum of alphas\n",
    "                            \n",
    "                            if(baseAlphas[idx] >= testAlphas[idx]):\n",
    "                                results[testClass][idx] = -1\n",
    "                            else : \n",
    "                                results[baseClass][idx] = -1\n",
    "            classScores = []       \n",
    "            \n",
    "            for boostClass in range(len(self.boosterList)):\n",
    "#                 print (results[boostClass].shape, \" \",classData[boostClass][\"test_y\"][i].shape)\n",
    "                \n",
    "                test_y = classData[boostClass][\"test_y\"][i]\n",
    "                sp = len(results[boostClass][results[boostClass]==classData[boostClass][\"test_y\"][i]])\n",
    "                tot = len(results[boostClass])\n",
    "                classScores.append(sp/tot)\n",
    "            scores.append(np.array(classScores).mean())\n",
    "        self.scores = np.array(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisBooster = multiAdabooster(len(classTrainTests), \"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisBooster.reset_params(rounds,classTrainTests[0][\"train_x\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-1affadd302a2>:131: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return  0.5 * np.log( (1.0 - weighted_error) / weighted_error )\n",
      "<ipython-input-2-1affadd302a2>:165: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weight = weight / np.sum(weight)\n",
      "<ipython-input-2-1affadd302a2>:131: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return  0.5 * np.log( (1.0 - weighted_error) / weighted_error )\n",
      "c:\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "irisBooster.fit(classTrainTests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76870748, 0.75510204, 0.71428571])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisBooster.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746031746031746"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"cust_iris_std\"] = irisBooster.scores.std()\n",
    "scores[\"cust_iris_mean\"] = irisBooster.scores.mean()\n",
    "scores[\"cust_iris_mean\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Iris Adabooster\n",
    "\n",
    "This is the implementation of the Sklearn adabooster, we have to make sure that we keep the 33% distribution representation in our test and train scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3  4\n",
       "0    5.1  3.5  1.4  0.2  0\n",
       "1    4.9  3.0  1.4  0.2  0\n",
       "2    4.7  3.2  1.3  0.2  0\n",
       "3    4.6  3.1  1.5  0.2  0\n",
       "4    5.0  3.6  1.4  0.2  0\n",
       "..   ...  ...  ...  ... ..\n",
       "145  6.7  3.0  5.2  2.3  2\n",
       "146  6.3  2.5  5.0  1.9  2\n",
       "147  6.5  3.0  5.2  2.0  2\n",
       "148  6.2  3.4  5.4  2.3  2\n",
       "149  5.9  3.0  5.1  1.8  2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF = pd.read_csv(\"iris.data\", header = None,index_col=False)\n",
    "irisDF[len(irisDF.columns)-1] = irisDF[len(irisDF.columns)-1].apply(lambda x: 0 if x=='Iris-setosa'  else (1 if x=='Iris-versicolor' else 2))\n",
    "\n",
    "X = irisDF[list(range(len(irisDF.columns)-1))].values\n",
    "Y = irisDF[len(irisDF.columns)-1].values\n",
    "irisDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for i in range(len(np.unique(Y))):\n",
    "    classes.append([X[Y==i],Y[Y==i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "train_x = []\n",
    "test_x = []\n",
    "train_y = []\n",
    "test_y = []\n",
    "for train_index, test_index in kf.split(classes[0][1]):\n",
    "    X, Y = classes[0][0],classes[0][1]\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    train_x.append(X_train)\n",
    "    test_x.append(X_test)\n",
    "    train_y.append(y_train)\n",
    "    test_y.append(y_test)\n",
    "#     Add the incorrect rows\n",
    "Yvals = irisDF[len(irisDF.columns)-1].values\n",
    "for j in np.unique(Yvals):\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(classes[j][1]):\n",
    "        X, Y = classes[j][0],classes[j][1]\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        train_x[i] = np.append(train_x[i], X_train, axis=0)   \n",
    "        test_x[i] = np.append(test_x[i],X_test, axis=0)\n",
    "        train_y[i] = np.append(train_y[i],y_train, axis=0)\n",
    "        test_y[i]= np.append(test_y[i],y_test, axis=0)\n",
    "        i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=rounds, random_state=0)\n",
    "\n",
    "Irisscores = []\n",
    "for i in range(len(train_x)):\n",
    "    \n",
    "    clf.fit(train_x[i], train_y[i])\n",
    "    Irisscores.append(clf.score(test_x[i], test_y[i]))\n",
    "Irisscores = np.array(Irisscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9699754901960785"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"ski_iris_std\"] = Irisscores.std()\n",
    "scores[\"ski_iris_mean\"] = Irisscores.mean()\n",
    "scores[\"ski_iris_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['CUST_SPAM','Skikit-SPAM',\"cust_iris_mean\",\"ski_iris_mean\"]\n",
    "\n",
    "ax.bar(langs,[scores[\"cust_spam_mean\"],scores[\"sci_spam_mean\"],scores[\"cust_iris_mean\"],scores[\"ski_iris_mean\"]],yerr = [scores[\"cust_spam_std\"],scores[\"sci_spam_std\"],scores[\"cust_iris_std\"],scores[\"ski_iris_std\"]], width = 0.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical dataset\n",
    "This is a set with 10 classes and more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3823 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  55  56  57  58  59  60  61  \\\n",
       "0      0   1   6  15  12   1   0   0   0   7  ...   0   0   0   6  14   7   1   \n",
       "1      0   0  10  16   6   0   0   0   0   7  ...   0   0   0  10  16  15   3   \n",
       "2      0   0   8  15  16  13   0   0   0   1  ...   0   0   0   9  14   0   0   \n",
       "3      0   0   0   3  11  16   0   0   0   0  ...   0   0   0   0   1  15   2   \n",
       "4      0   0   5  14   4   0   0   0   0   0  ...   0   0   0   4  12  14   7   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "3818   0   0   5  13  11   2   0   0   0   2  ...   0   0   0   8  13  15  10   \n",
       "3819   0   0   0   1  12   1   0   0   0   0  ...   0   0   0   0   4   9   0   \n",
       "3820   0   0   3  15   0   0   0   0   0   0  ...   0   0   0   4  14  16   9   \n",
       "3821   0   0   6  16   2   0   0   0   0   0  ...   0   0   0   5  16  16  16   \n",
       "3822   0   0   2  15  16  13   1   0   0   0  ...   0   0   0   4  14   1   0   \n",
       "\n",
       "      62  63  64  \n",
       "0      0   0   0  \n",
       "1      0   0   0  \n",
       "2      0   0   7  \n",
       "3      0   0   4  \n",
       "4      0   0   6  \n",
       "...   ..  ..  ..  \n",
       "3818   1   0   9  \n",
       "3819   0   0   4  \n",
       "3820   0   0   6  \n",
       "3821   5   0   6  \n",
       "3822   0   0   7  \n",
       "\n",
       "[3823 rows x 65 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opticalDF = pd.read_csv(\"optdigits.tra\", header = None,index_col=False)\n",
    "\n",
    "\n",
    "X = opticalDF[list(range(len(opticalDF.columns)-1))].values\n",
    "Y = opticalDF[len(opticalDF.columns)-1].values\n",
    "opticalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opticalDF[0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As you can see, there are errors in the dataset (columns are null) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx  0 :  [0]\n",
      "Idx  39 :  [0]\n"
     ]
    }
   ],
   "source": [
    "dropIDX = []\n",
    "for i in range(len(opticalDF.columns)):\n",
    "    if(len(opticalDF[i].unique()) == 1):\n",
    "        print(\"Idx \",i,\": \",opticalDF[i].unique())\n",
    "        dropIDX.append(i)\n",
    "opticalDF.drop(columns = dropIDX, inplace = True)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "opticalDF.columns = range(len(opticalDF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2548\n"
     ]
    }
   ],
   "source": [
    "dataGenerator = DataOrganizer(opticalDF)\n",
    "dataGenerator.split_into_classes()\n",
    "classTrainTests = dataGenerator.generate_train_test_splits_for_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3823 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  53  54  55  56  57  58  59  \\\n",
       "0      1   6  15  12   1   0   0   0   7  16  ...   0   0   0   6  14   7   1   \n",
       "1      0  10  16   6   0   0   0   0   7  16  ...   0   0   0  10  16  15   3   \n",
       "2      0   8  15  16  13   0   0   0   1  11  ...   0   0   0   9  14   0   0   \n",
       "3      0   0   3  11  16   0   0   0   0   5  ...   0   0   0   0   1  15   2   \n",
       "4      0   5  14   4   0   0   0   0   0  13  ...   0   0   0   4  12  14   7   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "3818   0   5  13  11   2   0   0   0   2  15  ...   0   0   0   8  13  15  10   \n",
       "3819   0   0   1  12   1   0   0   0   0   0  ...   0   0   0   0   4   9   0   \n",
       "3820   0   3  15   0   0   0   0   0   0  11  ...   0   0   0   4  14  16   9   \n",
       "3821   0   6  16   2   0   0   0   0   0  15  ...   0   0   0   5  16  16  16   \n",
       "3822   0   2  15  16  13   1   0   0   0   3  ...   0   0   0   4  14   1   0   \n",
       "\n",
       "      60  61  62  \n",
       "0      0   0   0  \n",
       "1      0   0   0  \n",
       "2      0   0   7  \n",
       "3      0   0   4  \n",
       "4      0   0   6  \n",
       "...   ..  ..  ..  \n",
       "3818   1   0   9  \n",
       "3819   0   0   4  \n",
       "3820   0   0   6  \n",
       "3821   5   0   6  \n",
       "3822   0   0   7  \n",
       "\n",
       "[3823 rows x 63 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opticalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "opticalBooster = multiAdabooster(len(classTrainTests), \"optical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "opticalBooster.reset_params(rounds,classTrainTests[0][\"train_x\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "opticalBooster.fit(classTrainTests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90400628, 0.89607227, 0.8871956 ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opticalBooster.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8957580518460331"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"cust_optical_std\"] = opticalBooster.scores.std()\n",
    "scores[\"cust_optical_mean\"] = opticalBooster.scores.mean()\n",
    "scores[\"cust_optical_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit learn Optical Implementation\n",
    "Before we can begin running the test, we need to ensure we have the correct population proportions for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 7, ..., 6, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = opticalDF[list(range(len(opticalDF.columns)-1))].values\n",
    "Y = opticalDF[len(opticalDF.columns)-1].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3823 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  53  54  55  56  57  58  59  \\\n",
       "0      1   6  15  12   1   0   0   0   7  16  ...   0   0   0   6  14   7   1   \n",
       "1      0  10  16   6   0   0   0   0   7  16  ...   0   0   0  10  16  15   3   \n",
       "2      0   8  15  16  13   0   0   0   1  11  ...   0   0   0   9  14   0   0   \n",
       "3      0   0   3  11  16   0   0   0   0   5  ...   0   0   0   0   1  15   2   \n",
       "4      0   5  14   4   0   0   0   0   0  13  ...   0   0   0   4  12  14   7   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "3818   0   5  13  11   2   0   0   0   2  15  ...   0   0   0   8  13  15  10   \n",
       "3819   0   0   1  12   1   0   0   0   0   0  ...   0   0   0   0   4   9   0   \n",
       "3820   0   3  15   0   0   0   0   0   0  11  ...   0   0   0   4  14  16   9   \n",
       "3821   0   6  16   2   0   0   0   0   0  15  ...   0   0   0   5  16  16  16   \n",
       "3822   0   2  15  16  13   1   0   0   0   3  ...   0   0   0   4  14   1   0   \n",
       "\n",
       "      60  61  62  \n",
       "0      0   0   0  \n",
       "1      0   0   0  \n",
       "2      0   0   7  \n",
       "3      0   0   4  \n",
       "4      0   0   6  \n",
       "...   ..  ..  ..  \n",
       "3818   1   0   9  \n",
       "3819   0   0   4  \n",
       "3820   0   0   6  \n",
       "3821   5   0   6  \n",
       "3822   0   0   7  \n",
       "\n",
       "[3823 rows x 63 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opticalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (np.unique(Y))\n",
    "len(Y[Y==9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for i in range(len(np.unique(Y))):\n",
    "    classes.append([X[Y==i],Y[Y==i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "train_x = []\n",
    "test_x = []\n",
    "train_y = []\n",
    "test_y = []\n",
    "for train_index, test_index in kf.split(classes[0][1]):\n",
    "    X, Y = classes[0][0],classes[0][1]\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    train_x.append(X_train)\n",
    "    test_x.append(X_test)\n",
    "    train_y.append(y_train)\n",
    "    test_y.append(y_test)\n",
    "#     Add the incorrect rows\n",
    "Yvals = opticalDF[len(opticalDF.columns)-1].values\n",
    "for j in np.unique(Yvals):\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(classes[j][1]):\n",
    "        X, Y = classes[j][0],classes[j][1]\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        train_x[i] = np.append(train_x[i], X_train, axis=0)   \n",
    "        test_x[i] = np.append(test_x[i],X_test, axis=0)\n",
    "        train_y[i] = np.append(train_y[i],y_train, axis=0)\n",
    "        test_y[i]= np.append(test_y[i],y_test, axis=0)\n",
    "        i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=rounds, random_state=0,algorithm=\"SAMME\")\n",
    "\n",
    "OpticalScores = []\n",
    "predictions = []\n",
    "for i in range(len(train_x)):\n",
    "    \n",
    "    clf.fit(train_x[i], train_y[i])\n",
    "    predictions.append(clf.predict(test_x[i]))\n",
    "    OpticalScores.append(clf.score(test_x[i], test_y[i]))\n",
    "OpticalScores = np.array(OpticalScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84259259, 0.82142857, 0.81648746])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OpticalScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268362064060989"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"ski_optical_std\"] = OpticalScores.std()\n",
    "scores[\"ski_optical_mean\"] = OpticalScores.mean()\n",
    "scores[\"ski_optical_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['CUST_SPAM','Skikit-SPAM',\"cust_iris\",\"ski_iris\",\"cust_opti\",\"ski_opti\"]\n",
    "\n",
    "ax.bar(langs,[scores[\"cust_spam_mean\"],scores[\"sci_spam_mean\"],scores[\"cust_iris_mean\"],scores[\"ski_iris_mean\"],scores[\"cust_optical_mean\"],scores[\"ski_optical_mean\"]],yerr = [scores[\"cust_spam_std\"],scores[\"sci_spam_std\"],scores[\"cust_iris_std\"],scores[\"ski_iris_std\"],scores[\"cust_optical_std\"],scores[\"ski_optical_std\"]], width = 0.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>81</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>42</td>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>86</td>\n",
       "      <td>34</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>42</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>49</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>44</td>\n",
       "      <td>77</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>35</td>\n",
       "      <td>51</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>59</td>\n",
       "      <td>65</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>96</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>94</td>\n",
       "      <td>86</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7494 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1   2    3    4    5    6    7   8   9    10  11   12  13   14  \\\n",
       "0      47  100  27   81   57   37   26    0   0  23   56  53  100  90   40   \n",
       "1       0   89  27  100   42   75   29   45  15  15   37   0   69   2  100   \n",
       "2       0   57  31   68   72   90  100  100  76  75   50  51   28  25   16   \n",
       "3       0  100   7   92    5   68   19   45  86  34  100  45   74  23   67   \n",
       "4       0   67  49   83  100  100   81   80  60  60   40  40   33  20   47   \n",
       "...   ...  ...  ..  ...  ...  ...  ...  ...  ..  ..  ...  ..  ...  ..  ...   \n",
       "7489    0   82   9   59   56   34   41    0  10  30    3  67   42  96  100   \n",
       "7490   49  100   0   70   24   56  100   65  86  85   44  77   21  38    6   \n",
       "7491  100   98  60  100   24   87    3   58  35  51   58  26   36   0    0   \n",
       "7492   59   65  91  100   84   96   72   50  51   8    0   0   45   1  100   \n",
       "7493    0   78  29  100   94   86   70   48  42  11   32   0   25  36  100   \n",
       "\n",
       "       15  16  \n",
       "0      98   8  \n",
       "1       6   2  \n",
       "2       0   1  \n",
       "3       0   4  \n",
       "4       0   1  \n",
       "...   ...  ..  \n",
       "7489  100   5  \n",
       "7490    0   4  \n",
       "7491    5   5  \n",
       "7492    0   1  \n",
       "7493   40   7  \n",
       "\n",
       "[7494 rows x 17 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penDF = pd.read_csv(\"pendigits.tra\", header = None,index_col=False)\n",
    "\n",
    "\n",
    "X = penDF[list(range(len(penDF.columns)-1))].values\n",
    "Y = penDF[len(penDF.columns)-1].values\n",
    "penDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4995\n"
     ]
    }
   ],
   "source": [
    "dataGenerator = DataOrganizer(penDF)\n",
    "dataGenerator.split_into_classes()\n",
    "classTrainTests = dataGenerator.generate_train_test_splits_for_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "penBooster = multiAdabooster(len(classTrainTests),\"pen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "penBooster.reset_params(rounds,classTrainTests[0][\"train_x\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "penBooster.fit(classTrainTests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90536644, 0.8917501 , 0.88978775])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penBooster.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8956347617140569"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"cust_pen_std\"] = penBooster.scores.std()\n",
    "scores[\"cust_pen_mean\"] = penBooster.scores.mean()\n",
    "scores[\"cust_pen_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for i in range(len(np.unique(Y))):\n",
    "    classes.append([X[Y==i],Y[Y==i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "train_x = []\n",
    "test_x = []\n",
    "train_y = []\n",
    "test_y = []\n",
    "for train_index, test_index in kf.split(classes[0][1]):\n",
    "    X, Y = classes[0][0],classes[0][1]\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    train_x.append(X_train)\n",
    "    test_x.append(X_test)\n",
    "    train_y.append(y_train)\n",
    "    test_y.append(y_test)\n",
    "#     Add the incorrect rows\n",
    "Yvals = opticalDF[len(opticalDF.columns)-1].values\n",
    "for j in np.unique(Yvals):\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(classes[j][1]):\n",
    "        X, Y = classes[j][0],classes[j][1]\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        train_x[i] = np.append(train_x[i], X_train, axis=0)   \n",
    "        test_x[i] = np.append(test_x[i],X_test, axis=0)\n",
    "        train_y[i] = np.append(train_y[i],y_train, axis=0)\n",
    "        test_y[i]= np.append(test_y[i],y_test, axis=0)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=rounds, random_state=0,algorithm=\"SAMME\")\n",
    "\n",
    "PenScores = []\n",
    "predictions = []\n",
    "for i in range(len(train_x)):\n",
    "    \n",
    "    clf.fit(train_x[i], train_y[i])\n",
    "    predictions.append(clf.predict(test_x[i]))\n",
    "    PenScores.append(clf.score(test_x[i], test_y[i]))\n",
    "PenScores = np.array(OpticalScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268362064060989"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"ski_pen_std\"] = PenScores.std()\n",
    "scores[\"ski_pen_mean\"] = PenScores.mean()\n",
    "scores[\"ski_pen_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['CUST_SPAM','Skikit-SPAM',\"cust_iris\",\"ski_iris\",\"cust_opti\",\"ski_opti\",\"cust_pen\",\"ski_pen\"]\n",
    "\n",
    "ax.bar(langs,[scores[\"cust_spam_mean\"],scores[\"sci_spam_mean\"],scores[\"cust_iris_mean\"],scores[\"ski_iris_mean\"],scores[\"cust_optical_mean\"],scores[\"ski_optical_mean\"], scores[\"cust_pen_mean\"], scores[\"ski_pen_mean\"]],yerr = [scores[\"cust_spam_std\"],scores[\"sci_spam_std\"],scores[\"cust_iris_std\"],scores[\"ski_iris_std\"],scores[\"cust_optical_std\"],scores[\"ski_optical_std\"],scores[\"cust_pen_std\"],scores[\"ski_pen_std\"]], width = 0.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   (4,)\n",
      "(4,)   (4,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2400x1600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cust_means, cust_std = np.array([scores[\"cust_spam_mean\"],scores[\"cust_iris_mean\"],scores[\"cust_optical_mean\"], scores[\"cust_pen_mean\"]]), np.array([scores[\"cust_spam_std\"],scores[\"cust_iris_std\"],scores[\"cust_optical_std\"],scores[\"cust_pen_std\"]])\n",
    "ski_means, ski_std   = np.array([scores[\"sci_spam_mean\"], scores[\"ski_iris_mean\"], scores[\"ski_optical_mean\"],  scores[\"ski_pen_mean\"]]),  np.array([scores[\"sci_spam_std\"], scores[\"ski_iris_std\"], scores[\"ski_optical_std\"], scores[\"ski_pen_std\"]])\n",
    "\n",
    "print(cust_means.shape, ' ', cust_std.shape)\n",
    "print(ski_means.shape, ' ', ski_std.shape)\n",
    "ind = np.arange(len(cust_means))  # the x locations for the groups\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "langs = ['Spam','Iris',\"Optical\",\"Pen\"]\n",
    "rects1 = ax.bar(ind - width/2, cust_means, width, yerr=cust_std,\n",
    "                label='Custom Adabooster')\n",
    "rects2 = ax.bar(ind + width/2, ski_means, width, yerr=ski_std,\n",
    "                label='SkiKit Adabooster ')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Score distribution for different tests')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(langs)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects, xpos='center'):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar in *rects*, displaying its height.\n",
    "\n",
    "    *xpos* indicates which side to place the text w.r.t. the center of\n",
    "    the bar. It can be one of the following {'center', 'right', 'left'}.\n",
    "    \"\"\"\n",
    "\n",
    "    ha = {'center': 'center', 'right': 'left', 'left': 'right'}\n",
    "    offset = {'center': 0, 'right': 1, 'left': -1}\n",
    "\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "\n",
    "\n",
    "autolabel(rects1, \"left\")\n",
    "autolabel(rects2, \"right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cust_spam_std': 0.06172346807611869,\n",
       " 'cust_spam_mean': 0.8817471295629343,\n",
       " 'sci_spam_std': 0.05148765507554833,\n",
       " 'sci_spam_mean': 0.91544160924376,\n",
       " 'cust_iris_std': 0.023124805050307368,\n",
       " 'cust_iris_mean': 0.746031746031746,\n",
       " 'ski_iris_std': 0.012038531068865509,\n",
       " 'ski_iris_mean': 0.9699754901960785,\n",
       " 'cust_optical_std': 0.006866528438607702,\n",
       " 'cust_optical_mean': 0.8957580518460331,\n",
       " 'ski_optical_std': 0.011322586178271997,\n",
       " 'ski_optical_mean': 0.8268362064060989,\n",
       " 'cust_pen_std': 0.006927812393346278,\n",
       " 'cust_pen_mean': 0.8956347617140569,\n",
       " 'ski_pen_std': 0.011322586178271997,\n",
       " 'ski_pen_mean': 0.8268362064060989}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
