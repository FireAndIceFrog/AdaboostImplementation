{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignement 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the assigment 1 by Mathew Lawrence 17354272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from os import path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating our own adabooster class. This will handle the adabooster for each scenario.\n",
    "\n",
    "For multiple types, we will create an adabooster which classifies \"that\" or \"not that\", respectfully, and then compare them to each other.\n",
    "\n",
    "The adabooster is a copy of tutorial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adabooster:\n",
    "    def __init__(self,debug = False, file = \"\"):\n",
    "        self.debug = debug\n",
    "        self.marginDF = None\n",
    "        self.classifier_df = None\n",
    "        self.file = file\n",
    "        self.fitNumber = 0\n",
    "        return\n",
    "    def saveClassifier(self, file=\"\"):\n",
    "        if(file!=\"\"):\n",
    "            self.file = file\n",
    "        self.classifier_df = pd.DataFrame(np.concatenate((self.h,np.expand_dims(self.alpha, axis=1)), axis = 1) , columns = [\"Threshold\",\"Feature\",\"Direction\",\"Alpha\"])\n",
    "        self.classifier_df.to_csv(self.file)\n",
    "    def loadClassifier(self,file = \"\"):\n",
    "        if(file!=\"\"):\n",
    "            self.file = file\n",
    "        self.classifier_df = pd.read_csv(self.file,index_col = 0)\n",
    "        \n",
    "    def reset_params(self,Tt, datat):\n",
    "        'Reset the parameters for the booster round'\n",
    "        \n",
    "        self.T = Tt\n",
    "        self.h  = np.zeros([self.T, 3], dtype=np.float64)\n",
    "        self.alpha  = np.zeros(self.T, dtype=np.float64)\n",
    "        self.err  = np.ones(self.T, dtype=np.float64) * np.inf\n",
    "        self.weight  = np.ones(datat.shape[0], dtype=np.float64) / datat.shape[0]\n",
    "        self.dim = datat.shape[1]\n",
    "        \n",
    "    def calculate_decision_stump_bad(self,x, w, l):\n",
    "                        # data x\n",
    "                        # weights w\n",
    "                        # labels l\n",
    "    \n",
    "        min_error = np.float64(np.inf)\n",
    "        best_thresh = 0\n",
    "        best_dir = 0\n",
    "        interval = np.abs(x.max() - x.min()) / 100.0\n",
    "        if(interval == 0):\n",
    "            return 0,1,np.inf\n",
    "        threshold = np.arange(x.min()-interval*2.0, x.max()+interval*2.0, interval)\n",
    "        temp_err = np.float64(0)\n",
    "\n",
    "        for d in [1, -1]:\n",
    "            for thresh in threshold:\n",
    "\n",
    "                temp = np.zeros(len(x), dtype=np.int64)\n",
    "                if(d == 1):\n",
    "                    temp = (x >= thresh)\n",
    "                else:\n",
    "                    temp = (x < thresh)\n",
    "\n",
    "                temp = np.int64(temp)\n",
    "                temp[np.where(temp == 0)] = -1\n",
    "\n",
    "                # Initialise actual and expected labels to a perfect match( 0 = match , 1 = not a match)\n",
    "                y = np.zeros(len(x), dtype=np.int64)            \n",
    "                # y will be an array where 0 indictes that the sample has been correctly classified, otherwise 1\n",
    "                y = np.int64(temp != l)\n",
    "\n",
    "                # Calculate error of this weak classifier on the weighted dataset\n",
    "                #========================\n",
    "                #YOUR CODE HERE\n",
    "                #========================\n",
    "                temp_err = np.sum(y * w)\n",
    "\n",
    "                if temp_err < min_error:\n",
    "                    #========================\n",
    "                    #YOUR CODE HERE\n",
    "                    #========================\n",
    "                    min_error = temp_err\n",
    "                    best_thresh = thresh\n",
    "                    best_dir = d                \n",
    "\n",
    "        return  best_thresh, best_dir, min_error\n",
    "    \n",
    "    def calculate_decision_stump(self,data, feature, weight, label):\n",
    "        'Calculate the desicion stump for the next booster round'\n",
    "        Tp=np.float64(0); #T+ total sum of positive examples weights\n",
    "        Tn=np.float64(0) #T- total sum of negative examples weights\n",
    "        Sp=np.float64(0) #S+ sum of positive weights below the cuurent threshold\n",
    "        Sn=np.float64(0) #S- sum of negative weights below the current threshold\n",
    "        error1=np.float64(0)\n",
    "        error2=np.float64(0)\n",
    "        min_error=np.float64(100) \n",
    "        min_thresh=np.float64(0) \n",
    "        direction=1\n",
    "\n",
    "        y = np.zeros(data.shape[0], dtype=np.int64)\n",
    "\n",
    "        #get all positive weights    \n",
    "        temp  = (label == 1)\n",
    "        temp = np.int64(temp)\n",
    "        Tp = np.sum(temp * weight)\n",
    "\n",
    "        #get all negative weights  \n",
    "        temp  = (label == -1)\n",
    "        temp = np.int64(temp)\n",
    "        Tn = np.sum(temp * weight)\n",
    "\n",
    "        #sort feature values\n",
    "        sorted_labels = data[:, feature].argsort()\n",
    "        sorted_vector =  data[sorted_labels]\n",
    "\n",
    "        length = len(sorted_vector)\n",
    "        for i in range(length):\n",
    "\n",
    "            #RIGHT DIRECTION THRESHOLD\n",
    "            #error1 is the sum of positives up to that point + total negatives minus the sum of negatives so far\n",
    "            error1 = Sp + (Tn - Sn) \n",
    "            if label[sorted_labels[i]] == -1 : \n",
    "                Sn = Sn +  weight[sorted_labels[i]]\n",
    "            else :\n",
    "                Sp = Sp + weight[sorted_labels[i]]\n",
    "\n",
    "            #LEFT DIRECTION THRESHOLD\n",
    "            error2 = Sn + (Tp - Sp) \n",
    "\n",
    "            if(min_error > error1) :\n",
    "                min_error = error1\n",
    "                min_thresh = sorted_vector[i, feature]\n",
    "                direction = 1\n",
    "            if(min_error > error2) :\n",
    "                min_error = error2\n",
    "                min_thresh = sorted_vector[i, feature]\n",
    "                direction = -1           \n",
    "        \n",
    "        return min_thresh, direction, min_error\n",
    "    def calculate_alpha(self,weighted_error):    \n",
    "        #========================\n",
    "        #YOUR CODE HERE\n",
    "        #========================\n",
    "        if(weighted_error == 0):\n",
    "            return 1\n",
    "        return  0.5 * np.log( (1.0 - weighted_error) / weighted_error )\n",
    "    \n",
    "    def classify_dataset_against_weak_classifier(self,x, thresh, direction):\n",
    "        classification = np.zeros(len(x))\n",
    "\n",
    "        #classifiy all samples based on the last feature\n",
    "        #get actual classification\n",
    "        for i in range(len(x)):\n",
    "            #========================\n",
    "            #YOUR CODE HERE\n",
    "            #========================\n",
    "            if direction == -1:\n",
    "                if x[i] < thresh: classification[i] = 1\n",
    "                else : classification[i] = -1\n",
    "            else:\n",
    "                if x[i] < thresh: classification[i] = -1\n",
    "                else : classification[i] = 1    \n",
    "\n",
    "\n",
    "        return classification \n",
    "    def update_weights(self,weight, alpha, classification, label):\n",
    "\n",
    "        for i in range(len(weight)):\n",
    "            #========================\n",
    "            #YOUR CODE HERE\n",
    "            #========================\n",
    "            weight[i] =  weight[i] * np.exp( -1.0 * alpha * classification[i] * label[i] ) \n",
    "\n",
    "        return weight\n",
    "    def normalise_weights(self,weight):\n",
    "\n",
    "        #========================\n",
    "        #YOUR CODE HERE\n",
    "        #========================\n",
    "        weight = weight / np.sum(weight)\n",
    "\n",
    "        return weight \n",
    "    def fit(self, x , label ):\n",
    "        # This is for future use\n",
    "        if(path.exists(self.file+str(self.fitNumber)+\".csv\")):\n",
    "            self.loadClassifier(self.file+str(self.fitNumber)+\".csv\")\n",
    "        else:\n",
    "            T = self.T\n",
    "            h = self.h\n",
    "            alpha = self.alpha\n",
    "            err = self.err\n",
    "            weight = self.weight\n",
    "\n",
    "            #0 - for each boosting round\n",
    "            for t in range(T): \n",
    "                #1 - iterate through every feature  \n",
    "\n",
    "\n",
    "                for feature in range(self.dim): \n",
    "                    weighted_error = np.float64(0)\n",
    "\n",
    "                    #========================\n",
    "                    #2 - GENERATE A DECISION STUMP FOR A FEATURE\n",
    "                    #YOUR CODE HERE\n",
    "                    #========================\n",
    "                    threshold, sign, weighted_error = self.calculate_decision_stump_bad(x[:,feature] , weight, label)\n",
    "    #                 threshold, sign, weighted_error = self.calculate_decision_stump(x , feature, weight, label)\n",
    "    #                 print(\"Iteration: \",t,\"Feature: \",feature, \" Weighted err: \", weighted_error)\n",
    "                    #========================\n",
    "                    #3 - KEEP TRACK OF THE FEATURE WITH THE LOWEST WEIGHTED ERROR\n",
    "                    #YOUR CODE HERE\n",
    "                    #========================        \n",
    "                    if weighted_error < err[t] :\n",
    "                        err[t] = weighted_error\n",
    "                        h[t][0] = threshold\n",
    "                        h[t][1] = feature\n",
    "                        h[t][2] = sign\n",
    "\n",
    "    #             print(\"---->Chosen ERR: \", err[t])\n",
    "                #========================\n",
    "                #4 - CALCULATE ALPHA FOR BOOSTING ROUND t\n",
    "                #YOUR CODE HERE\n",
    "                #========================            \n",
    "                alpha[t] = self.calculate_alpha(err[t])\n",
    "                #========================\n",
    "                #5 - CLASSIFY ALL SAMPLES BASED ON THE SELECTED FEATURE FOR BOOSTING ROUND t\n",
    "                #YOUR CODE HERE\n",
    "                #======================== \n",
    "                #print(x[:, int(h[t][1]) ])\n",
    "                classification = self.classify_dataset_against_weak_classifier(x[:, int(h[t][1]) ], h[t][0], h[t][2] )\n",
    "\n",
    "                #========================\n",
    "                #6 - UPDATE WEIGHTS BASED ON THE CORRECTNESS OF THE CLASSIFICATION\n",
    "                #YOUR CODE HERE\n",
    "                #========================   \n",
    "                weight = self.update_weights(weight, alpha[t], classification, label)\n",
    "\n",
    "                #========================\n",
    "                #7 - NORMALISE REASSIGNED WEIGHTS\n",
    "                #YOUR CODE HERE\n",
    "                #========================  \n",
    "                weight = self.normalise_weights(weight )\n",
    "\n",
    "                #--------------------------------------------\n",
    "                #BOOSTING ALGORITHM DONE\n",
    "                #--------------------------------------------\n",
    "                if(err[t]==0):\n",
    "                    break\n",
    "\n",
    "                if (self.debug):\n",
    "                    print(\"Round \",t, \" Done!\")\n",
    "            self.T = T\n",
    "            self.h = h\n",
    "            self.alpha =  alpha\n",
    "            self.err = err\n",
    "            self.weight = weight \n",
    "            self.saveClassifier(self.file+str(self.fitNumber)+\".csv\")\n",
    "        self.fitNumber = self.fitNumber+1\n",
    "#         self.classifier_df = pd.DataFrame(np.concatenate((self.h,np.expand_dims(self.alpha, axis=1)), axis = 1) , columns = [\"Threshold\",\"Feature\",\"Direction\",\"Alpha\"])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def classify_sample(self,xi ):\n",
    "        boost_classif = self.classifier_df\n",
    "        boost_classif = boost_classif.values\n",
    "        classification_sum = np.float64(0)\n",
    "\n",
    "        for thresh, feat, sign, alpha in boost_classif:\n",
    "            feat = np.int64(feat)\n",
    "            temp = np.float64(0)\n",
    "            if(sign == 1):\n",
    "                temp = (xi[feat] >= thresh)\n",
    "            else:\n",
    "                temp =  (xi[feat]< thresh)\n",
    "\n",
    "            temp = alpha*(-1 if temp == 0 else temp)\n",
    "\n",
    "\n",
    "            classification_sum = classification_sum + temp\n",
    "\n",
    "\n",
    "        if classification_sum >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    def classify_dataset(self,test_x):\n",
    "        results = []\n",
    "        for i in range(len(test_x)):\n",
    "            results.append(self.classify_sample(test_x[i]))\n",
    "        results = np.array(results)\n",
    "        return results\n",
    "    def score(self,test_x,test_y):\n",
    "        results=self.classify_dataset(test_x)\n",
    "        score = len(results[results == test_y])/len(results*100)\n",
    "        print(score)\n",
    "        return  score\n",
    "    def sum_classifier_votes_for_each_sample(self, dataset, df):\n",
    "        classifier_df = self.classifier_df\n",
    "        for i in range(len(dataset)):\n",
    "            classification_sum = np.float64(0)\n",
    "            neg_votes = np.float64(0)\n",
    "            pos_votes = np.float64(0)\n",
    "            for idx, thresh, feat, sign, alpha in classifier_df.itertuples():\n",
    "                #========================\n",
    "                #YOUR CODE HERE\n",
    "                #========================  \n",
    "                feat = np.int64(feat)\n",
    "                temp = np.float64(0)\n",
    "                if(sign == 1):\n",
    "                    temp = (dataset[i][feat] >= thresh)\n",
    "                else:\n",
    "                    temp =  (dataset[i][feat]< thresh)\n",
    "\n",
    "                temp = alpha*(-1 if temp == 0 else temp)\n",
    "                if temp < 0:\n",
    "                    neg_votes = neg_votes+temp\n",
    "                else : \n",
    "                    pos_votes = pos_votes +temp\n",
    "\n",
    "\n",
    "\n",
    "                classification_sum = classification_sum + temp\n",
    "\n",
    "\n",
    "            #========================\n",
    "            #YOUR CODE HERE\n",
    "            #========================  \n",
    "            df['sum_alpha'].iloc[i] = classification_sum\n",
    "            df['pos_votes'].iloc[i] = pos_votes\n",
    "            df['neg_votes'].iloc[i] = neg_votes\n",
    "\n",
    "        return df\n",
    "    def margin_calculation(self,sign, pos, neg, tot_votes):\n",
    "        #========================\n",
    "        #YOUR CODE HERE\n",
    "        #========================   \n",
    "        margin = (pos/tot_votes if sign>0 else neg/tot_votes)\n",
    "\n",
    "        return margin\n",
    "    def margin_calculation_for_training_samples(self, sign, pos, neg, tot_votes ):  \n",
    "        if np.sign(sign) < 0:\n",
    "            return np.abs(neg) / tot_votes, -1\n",
    "        else:\n",
    "            return pos / tot_votes, 1\n",
    "    def sign_of_margin(self, margin, classification, true_class_label):\n",
    "        #========================\n",
    "        #YOUR CODE HERE\n",
    "        #========================      \n",
    "        return (margin if (classification == true_class_label) else -margin)\n",
    "    def calculate_margins(self,x,label):\n",
    "        testing_set_df = pd.DataFrame(x)\n",
    "        testing_set_df['sum_alpha'] = 0 \n",
    "        testing_set_df['pos_votes'] = 0 \n",
    "        testing_set_df['neg_votes'] = 0 \n",
    "\n",
    "        testing_set_df = self.sum_classifier_votes_for_each_sample(x, testing_set_df)\n",
    "#         total_alpha_votes = np.sum(self.classifier_df.Alpha)\n",
    "#         testing_set_df['classification'] = 0\n",
    "#         testing_set_df['margin'] = 0\n",
    "#         testing_set_df['total_alpha_votes'] = total_alpha_votes\n",
    "        \n",
    "#         result = testing_set_df[['sum_alpha','pos_votes','neg_votes','total_alpha_votes']].apply(lambda x: self.margin_calculation_for_training_samples(*x), axis=1)\n",
    "#         testing_set_df['margin'] = result.apply(lambda x: x[0])\n",
    "#         testing_set_df['classification'] = result.apply(lambda x: x[1])\n",
    "#         testing_set_df['true_class_label'] = label\n",
    "        \n",
    "#         testing_set_df['sign_of_margin'] = testing_set_df[['margin', 'classification', 'true_class_label']].apply(lambda x: self.sign_of_margin(*x), axis=1)\n",
    "#         self.marginDF = testing_set_df[['sign_of_margin']]\n",
    "        self.marginDF =  testing_set_df\n",
    "        return testing_set_df\n",
    "    def plotMargins(self):\n",
    "        margin_30 = self.marginDF[[\"sign_of_margin\"]]\n",
    "        sns.kdeplot(margin_30.sign_of_margin, cumulative=True, label='classifier size 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X,Y,K=3):\n",
    "    'Split the data into train and test splits. They will be split into K buckets, with the K-1 bucket as the test dataset.'\n",
    "    kf = KFold(n_splits=K)\n",
    "    Y_correct = Y[Y==1]\n",
    "    Y_incorrect = Y[Y==-1]\n",
    "    X_correct = X[Y==1]\n",
    "    X_incorrect = X[Y==-1]\n",
    "\n",
    "    train_x = []\n",
    "    test_x = []\n",
    "    train_y = []\n",
    "    test_y = []\n",
    "\n",
    "    # Add the correct rows\n",
    "    for train_index, test_index in kf.split(Y_correct):\n",
    "        X_train, X_test = X_correct[train_index], X_correct[test_index]\n",
    "        y_train, y_test = Y_correct[train_index], Y_correct[test_index]\n",
    "\n",
    "        train_x.append(X_train)\n",
    "        test_x.append(X_test)\n",
    "        train_y.append(y_train)\n",
    "        test_y.append(y_test)\n",
    "    #     Add the incorrect rows\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(Y_incorrect):\n",
    "        X_train, X_test = X_incorrect[train_index], X_incorrect[test_index]\n",
    "        y_train, y_test = Y_incorrect[train_index], Y_incorrect[test_index]\n",
    "\n",
    "        train_x[i] = np.append(train_x[i], X_train, axis=0)   \n",
    "        test_x[i] = np.append(test_x[i],X_test, axis=0)\n",
    "        train_y[i] = np.append(train_y[i],y_train, axis=0)\n",
    "        test_y[i]= np.append(test_y[i],y_test, axis=0)\n",
    "        i = i + 1\n",
    "#     Make sure that all the indexes are the same.\n",
    "    minIndex =1000000000;\n",
    "    for i in range(len(train_x)):\n",
    "        if(train_x[i].shape[0] < minIndex):\n",
    "            minIndex = train_x[i].shape[0]\n",
    "    for i in range(len(train_x)):\n",
    "        train_x[i] = train_x[i][:minIndex]\n",
    "        train_y[i] = train_y[i][:minIndex]\n",
    "        \n",
    "    return \\\n",
    "    (train_x,\n",
    "    test_x,\n",
    "    train_y,\n",
    "    test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SPAM dataset should be placed in its own folder. Initiate it as SPAM_X and SPAM_Y, the input and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamDF = pd.read_csv(\"spambase.data\", header = None,index_col=False)\n",
    "SPAM_X = spamDF[list(range(len(spamDF.columns)-1))].values\n",
    "SPAM_Y = spamDF[len(spamDF.columns)-1].apply(lambda a: 1 if a==1 else -1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1:  0.6059552271245382\n",
      "1:  0.39404477287546186\n"
     ]
    }
   ],
   "source": [
    "print(\"-1: \",len(SPAM_X[SPAM_Y==-1])/len(SPAM_X))\n",
    "print(\"1: \",len(SPAM_X[SPAM_Y==1])/len(SPAM_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the SPAM dataset is skewed. we will have to make our bins with the same skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,    test_x,    train_y,    test_y = train_test_split(SPAM_X,SPAM_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1:  0.6060013046314416\n",
      "1:  0.39399869536855836\n"
     ]
    }
   ],
   "source": [
    "print(\"-1: \",len(train_y[0][train_y[0] == -1])/len(train_y[0]))\n",
    "print(\"1: \",len(train_y[0][train_y[0] == 1])/len(train_y[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataframe for the scores for the custom and the skikit adabooster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 60\n",
    "CUSTOM_SPAM_SCORES = []\n",
    "ADABOOST_SPAM_SCORES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "custSpamBoost = adabooster(False,\"spam\")\n",
    "custSpamBoost.reset_params(rounds, train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9224755700325733\n",
      "0.9282452707110241\n",
      "0.7945205479452054\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(train_x)):\n",
    "    custSpamBoost.fit(train_x[i], train_y[i])\n",
    "    CUSTOM_SPAM_SCORES.append( custSpamBoost.score(test_x[i],test_y[i]))\n",
    "CUSTOM_SPAM_SCORES = np.array(CUSTOM_SPAM_SCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92247557, 0.92824527, 0.79452055])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSTOM_SPAM_SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[\"cust_spam_std\"] = CUSTOM_SPAM_SCORES.std()\n",
    "scores[\"cust_spam_mean\"] = CUSTOM_SPAM_SCORES.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit learn adabooster Spam database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cust_spam_std': 0.06172346807611869, 'cust_spam_mean': 0.8817471295629343}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sciSpamBoost = AdaBoostClassifier(n_estimators=rounds, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_spam_scores = []\n",
    "for i in range(len(train_x)):\n",
    "    sciSpamBoost.fit(train_x[i], train_y[i])\n",
    "    sci_spam_scores.append(sciSpamBoost.score(test_x[i], test_y[i]))\n",
    "sci_spam_scores = np.array(sci_spam_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[\"sci_spam_std\"] = sci_spam_scores.std()\n",
    "scores[\"sci_spam_mean\"] = sci_spam_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cust_spam_std': 0.06172346807611869,\n",
       " 'cust_spam_mean': 0.8817471295629343,\n",
       " 'sci_spam_std': 0.05148765507554833,\n",
       " 'sci_spam_mean': 0.91544160924376}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['CUST_SPAM','Skikit-SPAM']\n",
    "\n",
    "ax.bar(langs,[scores[\"cust_spam_mean\"],scores[\"sci_spam_mean\"]],yerr = [scores[\"cust_spam_std\"],scores[\"sci_spam_std\"]], width = 0.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris database has got 3 classes. as such we will train 3 adaboosters and resolve conflicts using the sum of alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisDF = pd.read_csv(\"iris.data\", header = None,index_col=False)\n",
    "irisDF[len(irisDF.columns)-1] = irisDF[len(irisDF.columns)-1].apply(lambda x: 0 if x=='Iris-setosa'  else (1 if x=='Iris-versicolor' else 2))\n",
    "\n",
    "irisDF\n",
    "X = irisDF[list(range(len(irisDF.columns)-1))].values\n",
    "Y = irisDF[len(irisDF.columns)-1].values\n",
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3  4\n",
       "0    5.1  3.5  1.4  0.2  0\n",
       "1    4.9  3.0  1.4  0.2  0\n",
       "2    4.7  3.2  1.3  0.2  0\n",
       "3    4.6  3.1  1.5  0.2  0\n",
       "4    5.0  3.6  1.4  0.2  0\n",
       "..   ...  ...  ...  ... ..\n",
       "145  6.7  3.0  5.2  2.3  2\n",
       "146  6.3  2.5  5.0  1.9  2\n",
       "147  6.5  3.0  5.2  2.0  2\n",
       "148  6.2  3.4  5.4  2.3  2\n",
       "149  5.9  3.0  5.1  1.8  2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function to split the groups into however many classes there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataOrganizer:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        \n",
    "    def split_into_classes(self):\n",
    "        numClasses = self.df[len(self.df.columns)-1].unique()\n",
    "        classDF = []\n",
    "        for classID in numClasses:\n",
    "            dummyDF = self.df.copy()\n",
    "            dummyDF[len(dummyDF.columns)-1] = dummyDF[len(dummyDF.columns)-1].apply(lambda x: 1 if x == classID else -1)\n",
    "            classDF.append(dummyDF)\n",
    "        self.classDF = classDF\n",
    "    def generate_train_test_splits_for_classes(self, K=3):\n",
    "        'function to create a train and test split for each of the classes/adaboosters'\n",
    "        classTrainTests = []\n",
    "        for i in range(len(self.classDF)):\n",
    "\n",
    "            X = self.classDF[i][list(range(len(self.classDF[i].columns)-1))].values\n",
    "            Y = self.classDF[i][len(self.classDF[i].columns)-1].apply(lambda a: 1 if a==1 else -1).values\n",
    "\n",
    "            train_x,    test_x,    train_y,    test_y = train_test_split(X,Y,K)\n",
    "            \n",
    "            classTrainTests.append( {\n",
    "                \"train_x\" : train_x,\n",
    "                \"train_y\" : train_y,\n",
    "                \"test_x\" : test_x,\n",
    "                \"test_y\" : test_y\n",
    "            } )\n",
    "#         find the minimum for the train_x\n",
    "        minLen = np.inf\n",
    "        for i in range(len(self.classDF)):\n",
    "            for j in range(K):\n",
    "                currLen = len(classTrainTests[i][\"train_x\"][j])\n",
    "                if(minLen > currLen ):\n",
    "                    minLen = currLen\n",
    "        print(minLen)\n",
    "        for i in range(len(self.classDF)):\n",
    "            for j in range(K):\n",
    "                classTrainTests[i][\"train_x\"][j] = classTrainTests[i][\"train_x\"][j][:minLen]\n",
    "                classTrainTests[i][\"train_y\"][j] = classTrainTests[i][\"train_y\"][j][:minLen]\n",
    "                \n",
    "        minLen = np.inf   \n",
    "        for i in range(len(self.classDF)):\n",
    "            for j in range(K):\n",
    "                currLen = len(classTrainTests[i][\"test_x\"][j])\n",
    "                if(minLen > currLen ):\n",
    "                    minLen = currLen\n",
    "                    \n",
    "        for i in range(len(self.classDF)):\n",
    "            for j in range(K):\n",
    "                classTrainTests[i][\"test_x\"][j] = classTrainTests[i][\"test_x\"][j][:minLen]\n",
    "                classTrainTests[i][\"test_y\"][j] = classTrainTests[i][\"test_y\"][j][:minLen]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        self.classTrainTests = classTrainTests\n",
    "        return classTrainTests\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Organizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data organizer is used to split the data into class DF's (binary DF's) and generates N Dataframes where N = number of classes\n",
    "\n",
    "Next it splits the classes further into K-fold train/test splits\n",
    "\n",
    "\n",
    "In other words:\n",
    "1.) A DF with 3 classes is split into 3 DFs\n",
    "2.) Each DF is then split into K test/train splits of the order:\n",
    "Class:\n",
    "    train_x;\n",
    "        data\n",
    "        data\n",
    "        data\n",
    "    train_y;\n",
    "        data\n",
    "        data\n",
    "        data\n",
    "    test_x;\n",
    "        data\n",
    "        data\n",
    "        data\n",
    "    test_y;\n",
    "        data\n",
    "        data\n",
    "        data\n",
    "     ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGenerator = DataOrganizer(irisDF)\n",
    "dataGenerator.split_into_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "classTrainTests = dataGenerator.generate_train_test_splits_for_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train_x': [array([[5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3],\n",
       "          [6.5, 3. , 5.5, 1.8],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8]]),\n",
       "   array([[5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3]]),\n",
       "   array([[5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4]])],\n",
       "  'train_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)],\n",
       "  'test_x': [array([[5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ]]),\n",
       "   array([[5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3]]),\n",
       "   array([[4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8]])],\n",
       "  'test_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)]},\n",
       " {'train_x': [array([[5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3],\n",
       "          [6.5, 3. , 5.5, 1.8],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8]]),\n",
       "   array([[7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3]]),\n",
       "   array([[7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4]])],\n",
       "  'train_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)],\n",
       "  'test_x': [array([[7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4]]),\n",
       "   array([[5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3]]),\n",
       "   array([[5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8]])],\n",
       "  'test_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)]},\n",
       " {'train_x': [array([[7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4],\n",
       "          [5.6, 3. , 4.5, 1.5],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3]]),\n",
       "   array([[6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3],\n",
       "          [6.5, 3. , 5.5, 1.8],\n",
       "          [6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1]]),\n",
       "   array([[6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3],\n",
       "          [6.5, 3. , 5.5, 1.8],\n",
       "          [7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4],\n",
       "          [5.2, 4.1, 1.5, 0.1],\n",
       "          [5.5, 4.2, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3]])],\n",
       "  'train_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)],\n",
       "  'test_x': [array([[6.3, 3.3, 6. , 2.5],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [7.1, 3. , 5.9, 2.1],\n",
       "          [6.3, 2.9, 5.6, 1.8],\n",
       "          [6.5, 3. , 5.8, 2.2],\n",
       "          [7.6, 3. , 6.6, 2.1],\n",
       "          [4.9, 2.5, 4.5, 1.7],\n",
       "          [7.3, 2.9, 6.3, 1.8],\n",
       "          [6.7, 2.5, 5.8, 1.8],\n",
       "          [7.2, 3.6, 6.1, 2.5],\n",
       "          [6.5, 3.2, 5.1, 2. ],\n",
       "          [6.4, 2.7, 5.3, 1.9],\n",
       "          [6.8, 3. , 5.5, 2.1],\n",
       "          [5.7, 2.5, 5. , 2. ],\n",
       "          [5.8, 2.8, 5.1, 2.4],\n",
       "          [6.4, 3.2, 5.3, 2.3],\n",
       "          [6.5, 3. , 5.5, 1.8],\n",
       "          [5.1, 3.5, 1.4, 0.2],\n",
       "          [4.9, 3. , 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.3, 0.2],\n",
       "          [4.6, 3.1, 1.5, 0.2],\n",
       "          [5. , 3.6, 1.4, 0.2],\n",
       "          [5.4, 3.9, 1.7, 0.4],\n",
       "          [4.6, 3.4, 1.4, 0.3],\n",
       "          [5. , 3.4, 1.5, 0.2],\n",
       "          [4.4, 2.9, 1.4, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5.4, 3.7, 1.5, 0.2],\n",
       "          [4.8, 3.4, 1.6, 0.2],\n",
       "          [4.8, 3. , 1.4, 0.1],\n",
       "          [4.3, 3. , 1.1, 0.1],\n",
       "          [5.8, 4. , 1.2, 0.2],\n",
       "          [5.7, 4.4, 1.5, 0.4],\n",
       "          [5.4, 3.9, 1.3, 0.4],\n",
       "          [5.1, 3.5, 1.4, 0.3],\n",
       "          [5.7, 3.8, 1.7, 0.3],\n",
       "          [5.1, 3.8, 1.5, 0.3],\n",
       "          [5.4, 3.4, 1.7, 0.2],\n",
       "          [5.1, 3.7, 1.5, 0.4],\n",
       "          [4.6, 3.6, 1. , 0.2],\n",
       "          [5.1, 3.3, 1.7, 0.5],\n",
       "          [4.8, 3.4, 1.9, 0.2],\n",
       "          [5. , 3. , 1.6, 0.2],\n",
       "          [5. , 3.4, 1.6, 0.4],\n",
       "          [5.2, 3.5, 1.5, 0.2],\n",
       "          [5.2, 3.4, 1.4, 0.2],\n",
       "          [4.7, 3.2, 1.6, 0.2],\n",
       "          [4.8, 3.1, 1.6, 0.2],\n",
       "          [5.4, 3.4, 1.5, 0.4]]),\n",
       "   array([[7.7, 3.8, 6.7, 2.2],\n",
       "          [7.7, 2.6, 6.9, 2.3],\n",
       "          [6. , 2.2, 5. , 1.5],\n",
       "          [6.9, 3.2, 5.7, 2.3],\n",
       "          [5.6, 2.8, 4.9, 2. ],\n",
       "          [7.7, 2.8, 6.7, 2. ],\n",
       "          [6.3, 2.7, 4.9, 1.8],\n",
       "          [6.7, 3.3, 5.7, 2.1],\n",
       "          [7.2, 3.2, 6. , 1.8],\n",
       "          [6.2, 2.8, 4.8, 1.8],\n",
       "          [6.1, 3. , 4.9, 1.8],\n",
       "          [6.4, 2.8, 5.6, 2.1],\n",
       "          [7.2, 3. , 5.8, 1.6],\n",
       "          [7.4, 2.8, 6.1, 1.9],\n",
       "          [7.9, 3.8, 6.4, 2. ],\n",
       "          [6.4, 2.8, 5.6, 2.2],\n",
       "          [6.3, 2.8, 5.1, 1.5],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [5. , 3.2, 1.2, 0.2],\n",
       "          [5.5, 3.5, 1.3, 0.2],\n",
       "          [4.9, 3.1, 1.5, 0.1],\n",
       "          [4.4, 3. , 1.3, 0.2],\n",
       "          [5.1, 3.4, 1.5, 0.2],\n",
       "          [5. , 3.5, 1.3, 0.3],\n",
       "          [4.5, 2.3, 1.3, 0.3],\n",
       "          [4.4, 3.2, 1.3, 0.2],\n",
       "          [5. , 3.5, 1.6, 0.6],\n",
       "          [5.1, 3.8, 1.9, 0.4],\n",
       "          [4.8, 3. , 1.4, 0.3],\n",
       "          [5.1, 3.8, 1.6, 0.2],\n",
       "          [4.6, 3.2, 1.4, 0.2],\n",
       "          [5.3, 3.7, 1.5, 0.2],\n",
       "          [5. , 3.3, 1.4, 0.2],\n",
       "          [7. , 3.2, 4.7, 1.4],\n",
       "          [6.4, 3.2, 4.5, 1.5],\n",
       "          [6.9, 3.1, 4.9, 1.5],\n",
       "          [5.5, 2.3, 4. , 1.3],\n",
       "          [6.5, 2.8, 4.6, 1.5],\n",
       "          [5.7, 2.8, 4.5, 1.3],\n",
       "          [6.3, 3.3, 4.7, 1.6],\n",
       "          [4.9, 2.4, 3.3, 1. ],\n",
       "          [6.6, 2.9, 4.6, 1.3],\n",
       "          [5.2, 2.7, 3.9, 1.4],\n",
       "          [5. , 2. , 3.5, 1. ],\n",
       "          [5.9, 3. , 4.2, 1.5],\n",
       "          [6. , 2.2, 4. , 1. ],\n",
       "          [6.1, 2.9, 4.7, 1.4],\n",
       "          [5.6, 2.9, 3.6, 1.3],\n",
       "          [6.7, 3.1, 4.4, 1.4]]),\n",
       "   array([[6.1, 2.6, 5.6, 1.4],\n",
       "          [7.7, 3. , 6.1, 2.3],\n",
       "          [6.3, 3.4, 5.6, 2.4],\n",
       "          [6.4, 3.1, 5.5, 1.8],\n",
       "          [6. , 3. , 4.8, 1.8],\n",
       "          [6.9, 3.1, 5.4, 2.1],\n",
       "          [6.7, 3.1, 5.6, 2.4],\n",
       "          [6.9, 3.1, 5.1, 2.3],\n",
       "          [5.8, 2.7, 5.1, 1.9],\n",
       "          [6.8, 3.2, 5.9, 2.3],\n",
       "          [6.7, 3.3, 5.7, 2.5],\n",
       "          [6.7, 3. , 5.2, 2.3],\n",
       "          [6.3, 2.5, 5. , 1.9],\n",
       "          [6.5, 3. , 5.2, 2. ],\n",
       "          [6.2, 3.4, 5.4, 2.3],\n",
       "          [5.9, 3. , 5.1, 1.8],\n",
       "          [5.8, 2.7, 4.1, 1. ],\n",
       "          [6.2, 2.2, 4.5, 1.5],\n",
       "          [5.6, 2.5, 3.9, 1.1],\n",
       "          [5.9, 3.2, 4.8, 1.8],\n",
       "          [6.1, 2.8, 4. , 1.3],\n",
       "          [6.3, 2.5, 4.9, 1.5],\n",
       "          [6.1, 2.8, 4.7, 1.2],\n",
       "          [6.4, 2.9, 4.3, 1.3],\n",
       "          [6.6, 3. , 4.4, 1.4],\n",
       "          [6.8, 2.8, 4.8, 1.4],\n",
       "          [6.7, 3. , 5. , 1.7],\n",
       "          [6. , 2.9, 4.5, 1.5],\n",
       "          [5.7, 2.6, 3.5, 1. ],\n",
       "          [5.5, 2.4, 3.8, 1.1],\n",
       "          [5.5, 2.4, 3.7, 1. ],\n",
       "          [5.8, 2.7, 3.9, 1.2],\n",
       "          [6. , 2.7, 5.1, 1.6],\n",
       "          [5.4, 3. , 4.5, 1.5],\n",
       "          [6. , 3.4, 4.5, 1.6],\n",
       "          [6.7, 3.1, 4.7, 1.5],\n",
       "          [6.3, 2.3, 4.4, 1.3],\n",
       "          [5.6, 3. , 4.1, 1.3],\n",
       "          [5.5, 2.5, 4. , 1.3],\n",
       "          [5.5, 2.6, 4.4, 1.2],\n",
       "          [6.1, 3. , 4.6, 1.4],\n",
       "          [5.8, 2.6, 4. , 1.2],\n",
       "          [5. , 2.3, 3.3, 1. ],\n",
       "          [5.6, 2.7, 4.2, 1.3],\n",
       "          [5.7, 3. , 4.2, 1.2],\n",
       "          [5.7, 2.9, 4.2, 1.3],\n",
       "          [6.2, 2.9, 4.3, 1.3],\n",
       "          [5.1, 2.5, 3. , 1.1],\n",
       "          [5.7, 2.8, 4.1, 1.3]])],\n",
       "  'test_y': [array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64),\n",
       "   array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "         dtype=int64)]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classTrainTests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Adabooster\n",
    "Create a class which handles multiple adaboost classes and train it.\n",
    "\n",
    "The fit function fits the data to each model and it also scores the model each round.\n",
    "\n",
    "At the end it returns an array of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiAdabooster:\n",
    "    def __init__(self,numClasses, file):\n",
    "        self.boosterList = []\n",
    "        for i in range(numClasses):\n",
    "            self.boosterList.append(adabooster(False,file+str(i)))\n",
    "        \n",
    "    def reset_params(self, Tt, datat):\n",
    "        for i in range(len(self.boosterList)):\n",
    "            self.boosterList[i].reset_params(Tt, datat)\n",
    "    def fit(self,classData,rootFile = \"\"):\n",
    "        scores = []\n",
    "#     For each fold\n",
    "        for i in range(len(classData[0][\"train_x\"])):\n",
    "#         for each class fit\n",
    "            for boostClass in range(len(self.boosterList)):\n",
    "                train_x = classData[boostClass][\"train_x\"][i]\n",
    "                train_y = classData[boostClass][\"train_y\"][i]\n",
    "                self.boosterList[boostClass].fit(train_x,train_y)\n",
    "#         Set the margins for the classifier\n",
    "            results = []\n",
    "            for boostClass in range(len(self.boosterList)):\n",
    "                test_x = classData[boostClass][\"test_x\"][i]\n",
    "                test_y = classData[boostClass][\"test_y\"][i]\n",
    "                self.boosterList[boostClass].calculate_margins(test_x,test_y)\n",
    "                results.append(self.boosterList[boostClass].classify_dataset(test_x))\n",
    "#             use sum of alpha votes, if sum is greater, use that one.\n",
    "            for baseClass in range(len(results)):\n",
    "                baseAlphas = self.boosterList[baseClass].marginDF['sum_alpha']\n",
    "                for testClass in range(len(results)):\n",
    "                    if(testClass == baseClass):\n",
    "                        continue\n",
    "                    \n",
    "                    testAlphas = self.boosterList[testClass].marginDF['sum_alpha']\n",
    "                    for idx in range(len(results[baseClass])):\n",
    "                        if((results[baseClass][idx] == 1) and (results[testClass][idx]==1)):\n",
    "#                             get the sum of alphas\n",
    "                            \n",
    "                            if(baseAlphas[idx] >= testAlphas[idx]):\n",
    "                                results[testClass][idx] = -1\n",
    "                            else : \n",
    "                                results[baseClass][idx] = -1\n",
    "            classScores = []       \n",
    "            \n",
    "            for boostClass in range(len(self.boosterList)):\n",
    "#                 print (results[boostClass].shape, \" \",classData[boostClass][\"test_y\"][i].shape)\n",
    "                \n",
    "                test_y = classData[boostClass][\"test_y\"][i]\n",
    "                sp = len(results[boostClass][results[boostClass]==classData[boostClass][\"test_y\"][i]])\n",
    "                tot = len(results[boostClass])\n",
    "                classScores.append(sp/tot)\n",
    "            scores.append(np.array(classScores).mean())\n",
    "        self.scores = np.array(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisBooster = multiAdabooster(len(classTrainTests), \"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisBooster.reset_params(rounds,classTrainTests[0][\"train_x\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "irisBooster.fit(classTrainTests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76870748, 0.76190476, 0.71428571])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisBooster.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7482993197278911"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"cust_iris_std\"] = irisBooster.scores.std()\n",
    "scores[\"cust_iris_mean\"] = irisBooster.scores.mean()\n",
    "scores[\"cust_iris_mean\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Iris Adabooster\n",
    "\n",
    "This is the implementation of the Sklearn adabooster, we have to make sure that we keep the 33% distribution representation in our test and train scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3  4\n",
       "0    5.1  3.5  1.4  0.2  0\n",
       "1    4.9  3.0  1.4  0.2  0\n",
       "2    4.7  3.2  1.3  0.2  0\n",
       "3    4.6  3.1  1.5  0.2  0\n",
       "4    5.0  3.6  1.4  0.2  0\n",
       "..   ...  ...  ...  ... ..\n",
       "145  6.7  3.0  5.2  2.3  2\n",
       "146  6.3  2.5  5.0  1.9  2\n",
       "147  6.5  3.0  5.2  2.0  2\n",
       "148  6.2  3.4  5.4  2.3  2\n",
       "149  5.9  3.0  5.1  1.8  2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF = pd.read_csv(\"iris.data\", header = None,index_col=False)\n",
    "irisDF[len(irisDF.columns)-1] = irisDF[len(irisDF.columns)-1].apply(lambda x: 0 if x=='Iris-setosa'  else (1 if x=='Iris-versicolor' else 2))\n",
    "\n",
    "X = irisDF[list(range(len(irisDF.columns)-1))].values\n",
    "Y = irisDF[len(irisDF.columns)-1].values\n",
    "irisDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for i in range(len(np.unique(Y))):\n",
    "    classes.append([X[Y==i],Y[Y==i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "train_x = []\n",
    "test_x = []\n",
    "train_y = []\n",
    "test_y = []\n",
    "for train_index, test_index in kf.split(classes[0][1]):\n",
    "    X, Y = classes[0][0],classes[0][1]\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    train_x.append(X_train)\n",
    "    test_x.append(X_test)\n",
    "    train_y.append(y_train)\n",
    "    test_y.append(y_test)\n",
    "#     Add the incorrect rows\n",
    "Yvals = irisDF[len(irisDF.columns)-1].values\n",
    "for j in np.unique(Yvals):\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(classes[j][1]):\n",
    "        X, Y = classes[j][0],classes[j][1]\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        train_x[i] = np.append(train_x[i], X_train, axis=0)   \n",
    "        test_x[i] = np.append(test_x[i],X_test, axis=0)\n",
    "        train_y[i] = np.append(train_y[i],y_train, axis=0)\n",
    "        test_y[i]= np.append(test_y[i],y_test, axis=0)\n",
    "        i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=rounds, random_state=0)\n",
    "\n",
    "Irisscores = []\n",
    "for i in range(len(train_x)):\n",
    "    \n",
    "    clf.fit(train_x[i], train_y[i])\n",
    "    Irisscores.append(clf.score(test_x[i], test_y[i]))\n",
    "Irisscores = np.array(Irisscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9699754901960785"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"ski_iris_std\"] = Irisscores.std()\n",
    "scores[\"ski_iris_mean\"] = Irisscores.mean()\n",
    "scores[\"ski_iris_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['CUST_SPAM','Skikit-SPAM',\"cust_iris_mean\",\"ski_iris_mean\"]\n",
    "\n",
    "ax.bar(langs,[scores[\"cust_spam_mean\"],scores[\"sci_spam_mean\"],scores[\"cust_iris_mean\"],scores[\"ski_iris_mean\"]],yerr = [scores[\"cust_spam_std\"],scores[\"sci_spam_std\"],scores[\"cust_iris_std\"],scores[\"ski_iris_std\"]], width = 0.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical dataset\n",
    "This is a set with 10 classes and more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3823 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  55  56  57  58  59  60  61  \\\n",
       "0      0   1   6  15  12   1   0   0   0   7  ...   0   0   0   6  14   7   1   \n",
       "1      0   0  10  16   6   0   0   0   0   7  ...   0   0   0  10  16  15   3   \n",
       "2      0   0   8  15  16  13   0   0   0   1  ...   0   0   0   9  14   0   0   \n",
       "3      0   0   0   3  11  16   0   0   0   0  ...   0   0   0   0   1  15   2   \n",
       "4      0   0   5  14   4   0   0   0   0   0  ...   0   0   0   4  12  14   7   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "3818   0   0   5  13  11   2   0   0   0   2  ...   0   0   0   8  13  15  10   \n",
       "3819   0   0   0   1  12   1   0   0   0   0  ...   0   0   0   0   4   9   0   \n",
       "3820   0   0   3  15   0   0   0   0   0   0  ...   0   0   0   4  14  16   9   \n",
       "3821   0   0   6  16   2   0   0   0   0   0  ...   0   0   0   5  16  16  16   \n",
       "3822   0   0   2  15  16  13   1   0   0   0  ...   0   0   0   4  14   1   0   \n",
       "\n",
       "      62  63  64  \n",
       "0      0   0   0  \n",
       "1      0   0   0  \n",
       "2      0   0   7  \n",
       "3      0   0   4  \n",
       "4      0   0   6  \n",
       "...   ..  ..  ..  \n",
       "3818   1   0   9  \n",
       "3819   0   0   4  \n",
       "3820   0   0   6  \n",
       "3821   5   0   6  \n",
       "3822   0   0   7  \n",
       "\n",
       "[3823 rows x 65 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opticalDF = pd.read_csv(\"optdigits.tra\", header = None,index_col=False)\n",
    "\n",
    "\n",
    "X = opticalDF[list(range(len(opticalDF.columns)-1))].values\n",
    "Y = opticalDF[len(opticalDF.columns)-1].values\n",
    "opticalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opticalDF[0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As you can see, there are errors in the dataset (columns are null) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx  0 :  [0]\n",
      "Idx  39 :  [0]\n"
     ]
    }
   ],
   "source": [
    "dropIDX = []\n",
    "for i in range(len(opticalDF.columns)):\n",
    "    if(len(opticalDF[i].unique()) == 1):\n",
    "        print(\"Idx \",i,\": \",opticalDF[i].unique())\n",
    "        dropIDX.append(i)\n",
    "opticalDF.drop(columns = dropIDX, inplace = True)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "opticalDF.columns = range(len(opticalDF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2548\n"
     ]
    }
   ],
   "source": [
    "dataGenerator = DataOrganizer(opticalDF)\n",
    "dataGenerator.split_into_classes()\n",
    "classTrainTests = dataGenerator.generate_train_test_splits_for_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3823 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  53  54  55  56  57  58  59  \\\n",
       "0      1   6  15  12   1   0   0   0   7  16  ...   0   0   0   6  14   7   1   \n",
       "1      0  10  16   6   0   0   0   0   7  16  ...   0   0   0  10  16  15   3   \n",
       "2      0   8  15  16  13   0   0   0   1  11  ...   0   0   0   9  14   0   0   \n",
       "3      0   0   3  11  16   0   0   0   0   5  ...   0   0   0   0   1  15   2   \n",
       "4      0   5  14   4   0   0   0   0   0  13  ...   0   0   0   4  12  14   7   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "3818   0   5  13  11   2   0   0   0   2  15  ...   0   0   0   8  13  15  10   \n",
       "3819   0   0   1  12   1   0   0   0   0   0  ...   0   0   0   0   4   9   0   \n",
       "3820   0   3  15   0   0   0   0   0   0  11  ...   0   0   0   4  14  16   9   \n",
       "3821   0   6  16   2   0   0   0   0   0  15  ...   0   0   0   5  16  16  16   \n",
       "3822   0   2  15  16  13   1   0   0   0   3  ...   0   0   0   4  14   1   0   \n",
       "\n",
       "      60  61  62  \n",
       "0      0   0   0  \n",
       "1      0   0   0  \n",
       "2      0   0   7  \n",
       "3      0   0   4  \n",
       "4      0   0   6  \n",
       "...   ..  ..  ..  \n",
       "3818   1   0   9  \n",
       "3819   0   0   4  \n",
       "3820   0   0   6  \n",
       "3821   5   0   6  \n",
       "3822   0   0   7  \n",
       "\n",
       "[3823 rows x 63 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opticalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "opticalBooster = multiAdabooster(len(classTrainTests), \"optical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "opticalBooster.reset_params(rounds,classTrainTests[0][\"train_x\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "opticalBooster.fit(classTrainTests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90400628, 0.89607227, 0.8871956 ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opticalBooster.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8957580518460331"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"cust_optical_std\"] = opticalBooster.scores.std()\n",
    "scores[\"cust_optical_mean\"] = opticalBooster.scores.mean()\n",
    "scores[\"cust_optical_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit learn Optical Implementation\n",
    "Before we can begin running the test, we need to ensure we have the correct population proportions for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 7, ..., 6, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = opticalDF[list(range(len(opticalDF.columns)-1))].values\n",
    "Y = opticalDF[len(opticalDF.columns)-1].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3823 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  53  54  55  56  57  58  59  \\\n",
       "0      1   6  15  12   1   0   0   0   7  16  ...   0   0   0   6  14   7   1   \n",
       "1      0  10  16   6   0   0   0   0   7  16  ...   0   0   0  10  16  15   3   \n",
       "2      0   8  15  16  13   0   0   0   1  11  ...   0   0   0   9  14   0   0   \n",
       "3      0   0   3  11  16   0   0   0   0   5  ...   0   0   0   0   1  15   2   \n",
       "4      0   5  14   4   0   0   0   0   0  13  ...   0   0   0   4  12  14   7   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "3818   0   5  13  11   2   0   0   0   2  15  ...   0   0   0   8  13  15  10   \n",
       "3819   0   0   1  12   1   0   0   0   0   0  ...   0   0   0   0   4   9   0   \n",
       "3820   0   3  15   0   0   0   0   0   0  11  ...   0   0   0   4  14  16   9   \n",
       "3821   0   6  16   2   0   0   0   0   0  15  ...   0   0   0   5  16  16  16   \n",
       "3822   0   2  15  16  13   1   0   0   0   3  ...   0   0   0   4  14   1   0   \n",
       "\n",
       "      60  61  62  \n",
       "0      0   0   0  \n",
       "1      0   0   0  \n",
       "2      0   0   7  \n",
       "3      0   0   4  \n",
       "4      0   0   6  \n",
       "...   ..  ..  ..  \n",
       "3818   1   0   9  \n",
       "3819   0   0   4  \n",
       "3820   0   0   6  \n",
       "3821   5   0   6  \n",
       "3822   0   0   7  \n",
       "\n",
       "[3823 rows x 63 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opticalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (np.unique(Y))\n",
    "len(Y[Y==9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for i in range(len(np.unique(Y))):\n",
    "    classes.append([X[Y==i],Y[Y==i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "train_x = []\n",
    "test_x = []\n",
    "train_y = []\n",
    "test_y = []\n",
    "for train_index, test_index in kf.split(classes[0][1]):\n",
    "    X, Y = classes[0][0],classes[0][1]\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    train_x.append(X_train)\n",
    "    test_x.append(X_test)\n",
    "    train_y.append(y_train)\n",
    "    test_y.append(y_test)\n",
    "#     Add the incorrect rows\n",
    "Yvals = opticalDF[len(opticalDF.columns)-1].values\n",
    "for j in np.unique(Yvals):\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(classes[j][1]):\n",
    "        X, Y = classes[j][0],classes[j][1]\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        train_x[i] = np.append(train_x[i], X_train, axis=0)   \n",
    "        test_x[i] = np.append(test_x[i],X_test, axis=0)\n",
    "        train_y[i] = np.append(train_y[i],y_train, axis=0)\n",
    "        test_y[i]= np.append(test_y[i],y_test, axis=0)\n",
    "        i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=rounds, random_state=0,algorithm=\"SAMME\")\n",
    "\n",
    "OpticalScores = []\n",
    "predictions = []\n",
    "for i in range(len(train_x)):\n",
    "    \n",
    "    clf.fit(train_x[i], train_y[i])\n",
    "    predictions.append(clf.predict(test_x[i]))\n",
    "    OpticalScores.append(clf.score(test_x[i], test_y[i]))\n",
    "OpticalScores = np.array(OpticalScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84259259, 0.82142857, 0.81648746])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OpticalScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268362064060989"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"ski_optical_std\"] = OpticalScores.std()\n",
    "scores[\"ski_optical_mean\"] = OpticalScores.mean()\n",
    "scores[\"ski_optical_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['CUST_SPAM','Skikit-SPAM',\"cust_iris\",\"ski_iris\",\"cust_opti\",\"ski_opti\"]\n",
    "\n",
    "ax.bar(langs,[scores[\"cust_spam_mean\"],scores[\"sci_spam_mean\"],scores[\"cust_iris_mean\"],scores[\"ski_iris_mean\"],scores[\"cust_optical_mean\"],scores[\"ski_optical_mean\"]],yerr = [scores[\"cust_spam_std\"],scores[\"sci_spam_std\"],scores[\"cust_iris_std\"],scores[\"ski_iris_std\"],scores[\"cust_optical_std\"],scores[\"ski_optical_std\"]], width = 0.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>81</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>42</td>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>86</td>\n",
       "      <td>34</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>34</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>42</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>49</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>44</td>\n",
       "      <td>77</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>35</td>\n",
       "      <td>51</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>59</td>\n",
       "      <td>65</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>96</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>94</td>\n",
       "      <td>86</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7494 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1   2    3    4    5    6    7   8   9    10  11   12  13   14  \\\n",
       "0      47  100  27   81   57   37   26    0   0  23   56  53  100  90   40   \n",
       "1       0   89  27  100   42   75   29   45  15  15   37   0   69   2  100   \n",
       "2       0   57  31   68   72   90  100  100  76  75   50  51   28  25   16   \n",
       "3       0  100   7   92    5   68   19   45  86  34  100  45   74  23   67   \n",
       "4       0   67  49   83  100  100   81   80  60  60   40  40   33  20   47   \n",
       "...   ...  ...  ..  ...  ...  ...  ...  ...  ..  ..  ...  ..  ...  ..  ...   \n",
       "7489    0   82   9   59   56   34   41    0  10  30    3  67   42  96  100   \n",
       "7490   49  100   0   70   24   56  100   65  86  85   44  77   21  38    6   \n",
       "7491  100   98  60  100   24   87    3   58  35  51   58  26   36   0    0   \n",
       "7492   59   65  91  100   84   96   72   50  51   8    0   0   45   1  100   \n",
       "7493    0   78  29  100   94   86   70   48  42  11   32   0   25  36  100   \n",
       "\n",
       "       15  16  \n",
       "0      98   8  \n",
       "1       6   2  \n",
       "2       0   1  \n",
       "3       0   4  \n",
       "4       0   1  \n",
       "...   ...  ..  \n",
       "7489  100   5  \n",
       "7490    0   4  \n",
       "7491    5   5  \n",
       "7492    0   1  \n",
       "7493   40   7  \n",
       "\n",
       "[7494 rows x 17 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penDF = pd.read_csv(\"pendigits.tra\", header = None,index_col=False)\n",
    "\n",
    "\n",
    "X = penDF[list(range(len(penDF.columns)-1))].values\n",
    "Y = penDF[len(penDF.columns)-1].values\n",
    "penDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4995\n"
     ]
    }
   ],
   "source": [
    "dataGenerator = DataOrganizer(penDF)\n",
    "dataGenerator.split_into_classes()\n",
    "classTrainTests = dataGenerator.generate_train_test_splits_for_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "penBooster = multiAdabooster(len(classTrainTests),\"pen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "penBooster.reset_params(rounds,classTrainTests[0][\"train_x\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "penBooster.fit(classTrainTests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90536644, 0.8917501 , 0.88978775])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penBooster.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8956347617140569"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"cust_pen_std\"] = penBooster.scores.std()\n",
    "scores[\"cust_pen_mean\"] = penBooster.scores.mean()\n",
    "scores[\"cust_pen_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for i in range(len(np.unique(Y))):\n",
    "    classes.append([X[Y==i],Y[Y==i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "train_x = []\n",
    "test_x = []\n",
    "train_y = []\n",
    "test_y = []\n",
    "for train_index, test_index in kf.split(classes[0][1]):\n",
    "    X, Y = classes[0][0],classes[0][1]\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    train_x.append(X_train)\n",
    "    test_x.append(X_test)\n",
    "    train_y.append(y_train)\n",
    "    test_y.append(y_test)\n",
    "#     Add the incorrect rows\n",
    "Yvals = opticalDF[len(opticalDF.columns)-1].values\n",
    "for j in np.unique(Yvals):\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(classes[j][1]):\n",
    "        X, Y = classes[j][0],classes[j][1]\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        train_x[i] = np.append(train_x[i], X_train, axis=0)   \n",
    "        test_x[i] = np.append(test_x[i],X_test, axis=0)\n",
    "        train_y[i] = np.append(train_y[i],y_train, axis=0)\n",
    "        test_y[i]= np.append(test_y[i],y_test, axis=0)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=rounds, random_state=0,algorithm=\"SAMME\")\n",
    "\n",
    "PenScores = []\n",
    "predictions = []\n",
    "for i in range(len(train_x)):\n",
    "    \n",
    "    clf.fit(train_x[i], train_y[i])\n",
    "    predictions.append(clf.predict(test_x[i]))\n",
    "    PenScores.append(clf.score(test_x[i], test_y[i]))\n",
    "PenScores = np.array(OpticalScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268362064060989"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"ski_pen_std\"] = PenScores.std()\n",
    "scores[\"ski_pen_mean\"] = PenScores.mean()\n",
    "scores[\"ski_pen_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['CUST_SPAM','Skikit-SPAM',\"cust_iris\",\"ski_iris\",\"cust_opti\",\"ski_opti\",\"cust_pen\",\"ski_pen\"]\n",
    "\n",
    "ax.bar(langs,[scores[\"cust_spam_mean\"],scores[\"sci_spam_mean\"],scores[\"cust_iris_mean\"],scores[\"ski_iris_mean\"],scores[\"cust_optical_mean\"],scores[\"ski_optical_mean\"], scores[\"cust_pen_mean\"], scores[\"ski_pen_mean\"]],yerr = [scores[\"cust_spam_std\"],scores[\"sci_spam_std\"],scores[\"cust_iris_std\"],scores[\"ski_iris_std\"],scores[\"cust_optical_std\"],scores[\"ski_optical_std\"],scores[\"cust_pen_std\"],scores[\"ski_pen_std\"]], width = 0.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   (4,)\n",
      "(4,)   (4,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cust_means, cust_std = np.array([scores[\"cust_spam_mean\"],scores[\"cust_iris_mean\"],scores[\"cust_optical_mean\"], scores[\"cust_pen_mean\"]]), np.array([scores[\"cust_spam_std\"],scores[\"cust_iris_std\"],scores[\"cust_optical_std\"],scores[\"cust_pen_std\"]])\n",
    "ski_means, ski_std   = np.array([scores[\"sci_spam_mean\"], scores[\"ski_iris_mean\"], scores[\"ski_optical_mean\"],  scores[\"ski_pen_mean\"]]),  np.array([scores[\"sci_spam_std\"], scores[\"ski_iris_std\"], scores[\"ski_optical_std\"], scores[\"ski_pen_std\"]])\n",
    "\n",
    "print(cust_means.shape, ' ', cust_std.shape)\n",
    "print(ski_means.shape, ' ', ski_std.shape)\n",
    "ind = np.arange(len(cust_means))  # the x locations for the groups\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "langs = ['Spam','Iris',\"Optical\",\"Pen\"]\n",
    "rects1 = ax.bar(ind - width/2, cust_means, width, yerr=cust_std,\n",
    "                label='Custom Adabooster')\n",
    "rects2 = ax.bar(ind + width/2, ski_means, width, yerr=ski_std,\n",
    "                label='SkiKit Adabooster ')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Score distribution for different tests')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(langs)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects, xpos='center'):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar in *rects*, displaying its height.\n",
    "\n",
    "    *xpos* indicates which side to place the text w.r.t. the center of\n",
    "    the bar. It can be one of the following {'center', 'right', 'left'}.\n",
    "    \"\"\"\n",
    "\n",
    "    ha = {'center': 'center', 'right': 'left', 'left': 'right'}\n",
    "    offset = {'center': 0, 'right': 1, 'left': -1}\n",
    "\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "\n",
    "\n",
    "autolabel(rects1, \"left\")\n",
    "autolabel(rects2, \"right\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cust_spam_std': 0.06172346807611869,\n",
       " 'cust_spam_mean': 0.8817471295629343,\n",
       " 'sci_spam_std': 0.05148765507554833,\n",
       " 'sci_spam_mean': 0.91544160924376,\n",
       " 'cust_iris_std': 0.02421106179598931,\n",
       " 'cust_iris_mean': 0.7482993197278911,\n",
       " 'ski_iris_std': 0.012038531068865509,\n",
       " 'ski_iris_mean': 0.9699754901960785,\n",
       " 'cust_optical_std': 0.006866528438607702,\n",
       " 'cust_optical_mean': 0.8957580518460331,\n",
       " 'ski_optical_std': 0.011322586178271997,\n",
       " 'ski_optical_mean': 0.8268362064060989,\n",
       " 'cust_pen_std': 0.006927812393346278,\n",
       " 'cust_pen_mean': 0.8956347617140569,\n",
       " 'ski_pen_std': 0.011322586178271997,\n",
       " 'ski_pen_mean': 0.8268362064060989}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
